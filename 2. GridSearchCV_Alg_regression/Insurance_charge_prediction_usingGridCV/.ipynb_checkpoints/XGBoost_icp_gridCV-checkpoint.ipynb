{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e8ede9d-412d-463d-a6c0-1ff17d7612ad",
   "metadata": {},
   "source": [
    "# XG boost (eXtreme gradient boosting) Regressor Algorithm - insurance_charge_prediction\n",
    "# using Grid Search CV \n",
    "## MODEL CREATION PHASE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f7ff60-fe0e-4ec8-9dfe-5ea9b658ee13",
   "metadata": {},
   "source": [
    "## read the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f512fccb-e220-4abb-8870-abea1253083c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>16884.92400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>1725.55230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>4449.46200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>21984.47061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>3866.85520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>50</td>\n",
       "      <td>male</td>\n",
       "      <td>30.970</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>10600.54830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>18</td>\n",
       "      <td>female</td>\n",
       "      <td>31.920</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>2205.98080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>18</td>\n",
       "      <td>female</td>\n",
       "      <td>36.850</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>1629.83350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>21</td>\n",
       "      <td>female</td>\n",
       "      <td>25.800</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>2007.94500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>61</td>\n",
       "      <td>female</td>\n",
       "      <td>29.070</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>29141.36030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1338 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age     sex     bmi  children smoker      charges\n",
       "0      19  female  27.900         0    yes  16884.92400\n",
       "1      18    male  33.770         1     no   1725.55230\n",
       "2      28    male  33.000         3     no   4449.46200\n",
       "3      33    male  22.705         0     no  21984.47061\n",
       "4      32    male  28.880         0     no   3866.85520\n",
       "...   ...     ...     ...       ...    ...          ...\n",
       "1333   50    male  30.970         3     no  10600.54830\n",
       "1334   18  female  31.920         0     no   2205.98080\n",
       "1335   18  female  36.850         0     no   1629.83350\n",
       "1336   21  female  25.800         0     no   2007.94500\n",
       "1337   61  female  29.070         0    yes  29141.36030\n",
       "\n",
       "[1338 rows x 6 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "dataset = pd.read_csv(\"insurance_pre.csv\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b114e84-f389-4328-a61e-5d0f8ff7faf7",
   "metadata": {},
   "source": [
    "## convert categorical data into numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee3999b5-14b1-4acc-a477-d6038c4840d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>charges</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>smoker_yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>16884.92400</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>1725.55230</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>4449.46200</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>21984.47061</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>3866.85520</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>50</td>\n",
       "      <td>30.970</td>\n",
       "      <td>3</td>\n",
       "      <td>10600.54830</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>18</td>\n",
       "      <td>31.920</td>\n",
       "      <td>0</td>\n",
       "      <td>2205.98080</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>18</td>\n",
       "      <td>36.850</td>\n",
       "      <td>0</td>\n",
       "      <td>1629.83350</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>21</td>\n",
       "      <td>25.800</td>\n",
       "      <td>0</td>\n",
       "      <td>2007.94500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>61</td>\n",
       "      <td>29.070</td>\n",
       "      <td>0</td>\n",
       "      <td>29141.36030</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1338 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age     bmi  children      charges  sex_male  smoker_yes\n",
       "0      19  27.900         0  16884.92400         0           1\n",
       "1      18  33.770         1   1725.55230         1           0\n",
       "2      28  33.000         3   4449.46200         1           0\n",
       "3      33  22.705         0  21984.47061         1           0\n",
       "4      32  28.880         0   3866.85520         1           0\n",
       "...   ...     ...       ...          ...       ...         ...\n",
       "1333   50  30.970         3  10600.54830         1           0\n",
       "1334   18  31.920         0   2205.98080         0           0\n",
       "1335   18  36.850         0   1629.83350         0           0\n",
       "1336   21  25.800         0   2007.94500         0           0\n",
       "1337   61  29.070         0  29141.36030         0           1\n",
       "\n",
       "[1338 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.get_dummies(dataset,drop_first=True,dtype=int)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edad5f34-75eb-4d02-9c52-86281eb3d1b0",
   "metadata": {},
   "source": [
    "## split Input and Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e353955-35ca-4d22-ad86-ca7687a4246d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'bmi', 'children', 'charges', 'sex_male', 'smoker_yes'], dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62e67956-9f8d-4941-bfda-433b2c622f29",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>smoker_yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>50</td>\n",
       "      <td>30.970</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>18</td>\n",
       "      <td>31.920</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>18</td>\n",
       "      <td>36.850</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>21</td>\n",
       "      <td>25.800</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>61</td>\n",
       "      <td>29.070</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1338 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age     bmi  children  sex_male  smoker_yes\n",
       "0      19  27.900         0         0           1\n",
       "1      18  33.770         1         1           0\n",
       "2      28  33.000         3         1           0\n",
       "3      33  22.705         0         1           0\n",
       "4      32  28.880         0         1           0\n",
       "...   ...     ...       ...       ...         ...\n",
       "1333   50  30.970         3         1           0\n",
       "1334   18  31.920         0         0           0\n",
       "1335   18  36.850         0         0           0\n",
       "1336   21  25.800         0         0           0\n",
       "1337   61  29.070         0         0           1\n",
       "\n",
       "[1338 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "independent = dataset[['age', 'bmi', 'children',  'sex_male', 'smoker_yes' ]]\n",
    "independent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b2f27cf-9541-48d7-9545-8c287c2220b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16884.92400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1725.55230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4449.46200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21984.47061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3866.85520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>10600.54830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>2205.98080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>1629.83350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>2007.94500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>29141.36030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1338 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          charges\n",
       "0     16884.92400\n",
       "1      1725.55230\n",
       "2      4449.46200\n",
       "3     21984.47061\n",
       "4      3866.85520\n",
       "...           ...\n",
       "1333  10600.54830\n",
       "1334   2205.98080\n",
       "1335   1629.83350\n",
       "1336   2007.94500\n",
       "1337  29141.36030\n",
       "\n",
       "[1338 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dependent = dataset[['charges']]\n",
    "dependent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9360706b-2127-484c-9d87-8defbd5320aa",
   "metadata": {},
   "source": [
    "## split train and test set \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d84e048-ae08-4821-bed7-1668517d404a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(independent, dependent, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c86a7cc-fd07-4417-9dae-4763607cb5d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>smoker_yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>52</td>\n",
       "      <td>30.200</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>47</td>\n",
       "      <td>29.370</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>48</td>\n",
       "      <td>40.565</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1034</th>\n",
       "      <td>61</td>\n",
       "      <td>38.380</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>51</td>\n",
       "      <td>18.050</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1084</th>\n",
       "      <td>62</td>\n",
       "      <td>30.495</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>41</td>\n",
       "      <td>28.405</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1132</th>\n",
       "      <td>57</td>\n",
       "      <td>40.280</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725</th>\n",
       "      <td>30</td>\n",
       "      <td>39.050</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963</th>\n",
       "      <td>46</td>\n",
       "      <td>24.795</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>268 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age     bmi  children  sex_male  smoker_yes\n",
       "578    52  30.200         1         1           0\n",
       "610    47  29.370         1         0           0\n",
       "569    48  40.565         2         1           1\n",
       "1034   61  38.380         0         1           0\n",
       "198    51  18.050         0         0           0\n",
       "...   ...     ...       ...       ...         ...\n",
       "1084   62  30.495         2         0           0\n",
       "726    41  28.405         1         1           0\n",
       "1132   57  40.280         0         1           0\n",
       "725    30  39.050         3         0           1\n",
       "963    46  24.795         3         1           0\n",
       "\n",
       "[268 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8b9dfad-e3bb-49e3-8fe6-ae4e3def6654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>9724.53000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>8547.69130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>45702.02235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1034</th>\n",
       "      <td>12950.07120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>9644.25250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1084</th>\n",
       "      <td>15019.76005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>6664.68595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1132</th>\n",
       "      <td>20709.02034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725</th>\n",
       "      <td>40932.42950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963</th>\n",
       "      <td>9500.57305</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>268 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          charges\n",
       "578    9724.53000\n",
       "610    8547.69130\n",
       "569   45702.02235\n",
       "1034  12950.07120\n",
       "198    9644.25250\n",
       "...           ...\n",
       "1084  15019.76005\n",
       "726    6664.68595\n",
       "1132  20709.02034\n",
       "725   40932.42950\n",
       "963    9500.57305\n",
       "\n",
       "[268 rows x 1 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ab198e-cf89-49c9-95dc-35f9fe3e5ca1",
   "metadata": {},
   "source": [
    "## model creation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a5d9d5c-8cd4-43df-8332-83b0943431be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b45dc82-aa8b-42db-b8f2-4e3a38afd852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 384 candidates, totalling 1920 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    callbacks=None, colsample_bylevel=None,\n",
       "                                    colsample_bynode=None,\n",
       "                                    colsample_bytree=None, device=None,\n",
       "                                    early_stopping_rounds=None,\n",
       "                                    enable_categorical=False, eval_metric=None,\n",
       "                                    feature_types=None, feature_weights=None,\n",
       "                                    gamma=None, grow_policy=None,\n",
       "                                    importance_type=None,\n",
       "                                    interaction_constraints=None,\n",
       "                                    lear...\n",
       "                                    max_cat_to_onehot=None, max_delta_step=None,\n",
       "                                    max_depth=None, max_leaves=None,\n",
       "                                    min_child_weight=None, missing=nan,\n",
       "                                    monotone_constraints=None,\n",
       "                                    multi_strategy=None, n_estimators=None,\n",
       "                                    n_jobs=None, num_parallel_tree=None, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;colsample_bytree&#x27;: [0.5, 0.6, 0.7, 0.9],\n",
       "                         &#x27;learning_rate&#x27;: [1.0, 0.5, 0.1, 0.01, 0.03, 0.05],\n",
       "                         &#x27;n_estimators&#x27;: [50, 100, 150, 200],\n",
       "                         &#x27;subsample&#x27;: [0.5, 0.6, 0.7, 0.9]},\n",
       "             verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>GridSearchCV</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    callbacks=None, colsample_bylevel=None,\n",
       "                                    colsample_bynode=None,\n",
       "                                    colsample_bytree=None, device=None,\n",
       "                                    early_stopping_rounds=None,\n",
       "                                    enable_categorical=False, eval_metric=None,\n",
       "                                    feature_types=None, feature_weights=None,\n",
       "                                    gamma=None, grow_policy=None,\n",
       "                                    importance_type=None,\n",
       "                                    interaction_constraints=None,\n",
       "                                    lear...\n",
       "                                    max_cat_to_onehot=None, max_delta_step=None,\n",
       "                                    max_depth=None, max_leaves=None,\n",
       "                                    min_child_weight=None, missing=nan,\n",
       "                                    monotone_constraints=None,\n",
       "                                    multi_strategy=None, n_estimators=None,\n",
       "                                    n_jobs=None, num_parallel_tree=None, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;colsample_bytree&#x27;: [0.5, 0.6, 0.7, 0.9],\n",
       "                         &#x27;learning_rate&#x27;: [1.0, 0.5, 0.1, 0.01, 0.03, 0.05],\n",
       "                         &#x27;n_estimators&#x27;: [50, 100, 150, 200],\n",
       "                         &#x27;subsample&#x27;: [0.5, 0.6, 0.7, 0.9]},\n",
       "             verbose=3)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>best_estimator_: XGBRegressor</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=0.9, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             feature_weights=None, gamma=None, grow_policy=None,\n",
       "             importance_type=None, interaction_constraints=None,\n",
       "             learning_rate=0.03, max_bin=None, max_cat_threshold=None,\n",
       "             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "             max_leaves=None, min_child_weight=None, missing=nan,\n",
       "             monotone_constraints=None, multi_strategy=None, n_estimators=150,\n",
       "             n_jobs=None, num_parallel_tree=None, ...)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>XGBRegressor</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor\">?<span>Documentation for XGBRegressor</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=0.9, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             feature_weights=None, gamma=None, grow_policy=None,\n",
       "             importance_type=None, interaction_constraints=None,\n",
       "             learning_rate=0.03, max_bin=None, max_cat_threshold=None,\n",
       "             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "             max_leaves=None, min_child_weight=None, missing=nan,\n",
       "             monotone_constraints=None, multi_strategy=None, n_estimators=150,\n",
       "             n_jobs=None, num_parallel_tree=None, ...)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    callbacks=None, colsample_bylevel=None,\n",
       "                                    colsample_bynode=None,\n",
       "                                    colsample_bytree=None, device=None,\n",
       "                                    early_stopping_rounds=None,\n",
       "                                    enable_categorical=False, eval_metric=None,\n",
       "                                    feature_types=None, feature_weights=None,\n",
       "                                    gamma=None, grow_policy=None,\n",
       "                                    importance_type=None,\n",
       "                                    interaction_constraints=None,\n",
       "                                    lear...\n",
       "                                    max_cat_to_onehot=None, max_delta_step=None,\n",
       "                                    max_depth=None, max_leaves=None,\n",
       "                                    min_child_weight=None, missing=nan,\n",
       "                                    monotone_constraints=None,\n",
       "                                    multi_strategy=None, n_estimators=None,\n",
       "                                    n_jobs=None, num_parallel_tree=None, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'colsample_bytree': [0.5, 0.6, 0.7, 0.9],\n",
       "                         'learning_rate': [1.0, 0.5, 0.1, 0.01, 0.03, 0.05],\n",
       "                         'n_estimators': [50, 100, 150, 200],\n",
       "                         'subsample': [0.5, 0.6, 0.7, 0.9]},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"\"\" \n",
    "# hyper parameters :  n_estimators, learning_rate, max_depth, subsample, colsample_bytree\n",
    "# \"\"\"\n",
    "\n",
    "# regressor = xgb.XGBRegressor(\n",
    "#     objective='reg:squarederror',\n",
    "#     eval_metric='rmse',\n",
    "#     random_state=0,\n",
    "#     n_estimators=60,\n",
    "#     learning_rate=0.1,\n",
    "#     max_depth=3,\n",
    "#     subsample=0.9,\n",
    "#     colsample_bytree=0.8\n",
    "# )\n",
    "# regressor.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "  \"n_estimators\":[50,100,150,200],\n",
    "    \"learning_rate\":[1.0,0.5,0.1,0.01,0.03,0.05],\n",
    "    \"subsample\":[0.5,0.6,0.7,0.9],\n",
    "    \"colsample_bytree\":[0.5,0.6,0.7,0.9]\n",
    "}\n",
    "\n",
    "model=xgb.XGBRegressor()\n",
    "\n",
    "grid_model = GridSearchCV(model, param_grid, refit=True, verbose=3, n_jobs=-1)\n",
    "\n",
    "grid_model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d52dc9-38d5-4bc4-9f9f-f921f9ae8723",
   "metadata": {},
   "source": [
    "## Grid Search CV results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba58b915-cb93-45a7-8f3f-91507f60a0ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.07504916, 0.07343559, 0.08249364, 0.07589903, 0.12282414,\n",
       "        0.13136587, 0.12048659, 0.12197967, 0.19600124, 0.17079625,\n",
       "        0.17252202, 0.22029467, 0.45155396, 0.29682407, 0.33666945,\n",
       "        0.33268404, 0.08817348, 0.10334845, 0.09503369, 0.23533573,\n",
       "        0.16617665, 0.20912271, 0.2267602 , 0.1860981 , 0.34812551,\n",
       "        0.23182631, 0.30792184, 0.2030941 , 0.30795803, 0.38232522,\n",
       "        0.31910744, 0.35833874, 0.11770015, 0.10808568, 0.1034761 ,\n",
       "        0.11744065, 0.16575522, 0.23601174, 0.16759281, 0.18212905,\n",
       "        0.28397069, 0.27546668, 0.26701145, 0.24088531, 0.2811296 ,\n",
       "        0.30059233, 0.30227876, 0.28714061, 0.09207807, 0.09975791,\n",
       "        0.09524055, 0.09124107, 0.16013179, 0.51211305, 0.18614097,\n",
       "        0.16453042, 0.25517726, 0.41398716, 0.37186136, 0.36443281,\n",
       "        0.51925073, 0.61066699, 0.29840703, 0.43090792, 0.0981154 ,\n",
       "        0.08894448, 0.09620652, 0.10941911, 0.19763126, 0.16926141,\n",
       "        0.15821552, 0.15674443, 0.22256899, 0.20532756, 0.23274646,\n",
       "        0.21980367, 0.29957151, 0.30818381, 0.31784911, 0.34656172,\n",
       "        0.0793642 , 0.08161407, 0.21421556, 0.10414562, 0.16047688,\n",
       "        0.19985938, 0.1475925 , 0.18119054, 0.25609107, 0.20687122,\n",
       "        0.22649632, 0.22170138, 0.34630299, 0.38041468, 0.25637827,\n",
       "        0.28313642, 0.23039532, 0.09077997, 0.09470487, 0.08666239,\n",
       "        0.15685253, 0.16446166, 0.21249952, 0.27181344, 0.24691854,\n",
       "        0.24926453, 0.24233189, 0.28119025, 0.62443714, 0.31921983,\n",
       "        0.31876135, 0.32365088, 0.08794875, 0.09017873, 0.09853821,\n",
       "        0.14412627, 0.34698739, 0.41129932, 0.18517194, 0.15380964,\n",
       "        0.26993537, 0.23901377, 0.25518799, 0.23928952, 0.32121339,\n",
       "        0.33694911, 0.3627461 , 0.28198514, 0.0904397 , 0.08424025,\n",
       "        0.08973336, 0.08541389, 0.14206638, 0.16615667, 0.20558581,\n",
       "        0.21425076, 0.27472339, 0.21865816, 0.2226881 , 0.21344829,\n",
       "        0.27459717, 0.28860321, 0.30094404, 0.27947068, 0.0802177 ,\n",
       "        0.0796864 , 0.07892451, 0.10173435, 0.18439031, 0.14307332,\n",
       "        0.1463995 , 0.50581269, 0.35163193, 0.25433321, 0.26518617,\n",
       "        0.29831586, 0.33848405, 0.32405148, 0.3040206 , 0.36783218,\n",
       "        0.0837256 , 0.10262966, 0.12261443, 0.08627095, 0.14911981,\n",
       "        0.15254583, 0.16945705, 0.15653954, 0.25936966, 0.20726757,\n",
       "        0.24746847, 0.24339504, 0.3295857 , 0.29289718, 0.34288459,\n",
       "        0.34260178, 0.10048137, 0.10513372, 0.098774  , 0.09263177,\n",
       "        0.36932321, 0.16174011, 0.38283682, 0.21556296, 0.30623522,\n",
       "        0.31401534, 0.24662414, 0.22733274, 0.2815587 , 0.27304363,\n",
       "        0.28929834, 0.2871016 , 0.08438277, 0.09254761, 0.08636107,\n",
       "        0.08938675, 0.19714704, 0.17252612, 0.16843581, 0.51841879,\n",
       "        0.2556489 , 0.43731956, 0.39865022, 0.35150228, 0.35094595,\n",
       "        0.47979264, 0.80182023, 0.9237772 , 0.18849721, 0.13818498,\n",
       "        0.2355926 , 0.18038788, 0.20128136, 0.21028767, 0.20260139,\n",
       "        0.18591127, 0.26699324, 0.26430559, 0.2943296 , 0.26334724,\n",
       "        0.34357991, 0.32502384, 0.35460343, 0.3425477 , 0.0977448 ,\n",
       "        0.09845119, 0.09404521, 0.1072897 , 0.16869121, 0.16782742,\n",
       "        0.17707253, 0.17291212, 0.25916376, 0.29598079, 0.25940585,\n",
       "        0.27664747, 0.33410401, 0.35304527, 0.34407873, 0.80523233,\n",
       "        0.11259708, 0.09512243, 0.09672623, 0.1109076 , 0.16763391,\n",
       "        0.17772622, 0.17941608, 0.17930622, 0.2421567 , 0.26305704,\n",
       "        0.26580739, 0.25860095, 0.32298245, 0.32215772, 0.53503895,\n",
       "        0.62377343, 0.10206647, 0.09503422, 0.10476508, 0.09611831,\n",
       "        0.16866245, 0.16819735, 0.16674981, 0.19416289, 0.25436282,\n",
       "        0.25406127, 0.25068955, 0.278229  , 0.30970554, 0.32343798,\n",
       "        0.6049264 , 0.36741738, 0.1089654 , 0.12091503, 0.10301967,\n",
       "        0.11369739, 0.17306404, 0.17926779, 0.17293897, 0.23406377,\n",
       "        0.36498337, 0.37457757, 0.42504869, 0.41163373, 0.4271955 ,\n",
       "        0.41945095, 0.34095678, 0.33785901, 0.12669435, 0.19024935,\n",
       "        0.13650513, 0.18188705, 0.26691875, 0.29838452, 0.32617779,\n",
       "        0.46406736, 0.79218211, 0.7293838 , 0.54841509, 0.4726357 ,\n",
       "        0.59476523, 0.47289758, 0.44487748, 0.44438529, 0.16993594,\n",
       "        0.16897554, 0.13820529, 0.14198713, 0.20007324, 0.22872734,\n",
       "        0.20233665, 0.21485996, 0.33931031, 0.30498676, 0.31955247,\n",
       "        0.30676379, 0.38039951, 0.47448654, 0.44584575, 0.36481185,\n",
       "        0.11868052, 0.12067943, 0.11146584, 0.12074313, 0.18997216,\n",
       "        0.21543827, 0.18420534, 0.22776151, 0.30202875, 0.29720149,\n",
       "        0.28629718, 0.29661098, 0.39684305, 0.38732853, 0.36334953,\n",
       "        0.37128944, 0.10950289, 0.10315866, 0.10419779, 0.10943179,\n",
       "        0.21108141, 0.19316955, 0.18392086, 0.19252529, 0.27760825,\n",
       "        0.27908554, 0.29462924, 0.31671977, 0.3816215 , 0.4105978 ,\n",
       "        0.41128445, 0.36420307, 0.11034255, 0.11485295, 0.11095295,\n",
       "        0.12027721, 0.20883923, 0.23066087, 0.21411314, 0.20466619,\n",
       "        0.28264098, 0.31038132, 0.28787556, 0.27761526, 0.37360559,\n",
       "        0.36432366, 0.39580531, 0.36998062, 0.12730031, 0.11643457,\n",
       "        0.1174027 , 0.11190281, 0.19771066, 0.19633169, 0.19487653,\n",
       "        0.19217081, 0.29124775, 0.30256557, 0.31102662, 0.30217633,\n",
       "        0.36533289, 0.39258213, 0.36840963, 0.38797064]),\n",
       " 'std_fit_time': array([0.00615   , 0.00394433, 0.00728218, 0.00193636, 0.0099787 ,\n",
       "        0.00551385, 0.00290255, 0.00818201, 0.02095646, 0.0015869 ,\n",
       "        0.00479731, 0.04383868, 0.2035173 , 0.03113729, 0.11552196,\n",
       "        0.05314252, 0.0112014 , 0.03740473, 0.01968661, 0.1060362 ,\n",
       "        0.02763013, 0.07919784, 0.0626083 , 0.051925  , 0.05384249,\n",
       "        0.01313572, 0.09075117, 0.0178894 , 0.02693725, 0.0563882 ,\n",
       "        0.03781578, 0.06166441, 0.01426199, 0.01164814, 0.01933217,\n",
       "        0.01258411, 0.024059  , 0.11941541, 0.02393994, 0.01861915,\n",
       "        0.12423737, 0.07591477, 0.06292515, 0.0116484 , 0.0354276 ,\n",
       "        0.03149987, 0.02263562, 0.03633475, 0.01652021, 0.01974374,\n",
       "        0.01173984, 0.00449052, 0.01639271, 0.41523606, 0.05983953,\n",
       "        0.0323218 , 0.08983176, 0.05080261, 0.22574586, 0.16199242,\n",
       "        0.22519619, 0.24100844, 0.00660928, 0.03935686, 0.01103441,\n",
       "        0.00829916, 0.01638687, 0.01827564, 0.02209835, 0.02103068,\n",
       "        0.01631018, 0.01668281, 0.01892853, 0.01706382, 0.0287459 ,\n",
       "        0.02057663, 0.0172515 , 0.04062445, 0.03713315, 0.02337831,\n",
       "        0.00572787, 0.01026407, 0.11214809, 0.02483462, 0.0244318 ,\n",
       "        0.041116  , 0.01755741, 0.02125088, 0.03179738, 0.01084322,\n",
       "        0.02296774, 0.02057487, 0.07837817, 0.11381046, 0.0165321 ,\n",
       "        0.01526563, 0.12814811, 0.00579662, 0.00431875, 0.00241297,\n",
       "        0.01823873, 0.01418161, 0.02631096, 0.0453649 , 0.01466376,\n",
       "        0.03091662, 0.04834859, 0.0443357 , 0.26235083, 0.02110876,\n",
       "        0.01101533, 0.0070493 , 0.0043961 , 0.00686786, 0.01417258,\n",
       "        0.02125745, 0.20342135, 0.19615991, 0.0155271 , 0.01617262,\n",
       "        0.02044005, 0.03197746, 0.01909063, 0.03751716, 0.03142657,\n",
       "        0.05280684, 0.02516512, 0.01626131, 0.00491176, 0.00321999,\n",
       "        0.00806951, 0.00534692, 0.00674638, 0.02296274, 0.0459934 ,\n",
       "        0.02352335, 0.03025553, 0.01501717, 0.01510006, 0.01631926,\n",
       "        0.00955583, 0.01844526, 0.02278713, 0.01527767, 0.00415641,\n",
       "        0.00327123, 0.00226617, 0.02390482, 0.02374084, 0.00628075,\n",
       "        0.00867513, 0.32896572, 0.01056817, 0.02451676, 0.00930364,\n",
       "        0.02022104, 0.03860752, 0.03094747, 0.01435437, 0.04333786,\n",
       "        0.00465299, 0.00963466, 0.01066439, 0.00993141, 0.00764315,\n",
       "        0.00583746, 0.00640581, 0.01836111, 0.01530347, 0.00874617,\n",
       "        0.02714522, 0.01992906, 0.03645267, 0.01490181, 0.0395931 ,\n",
       "        0.02848041, 0.00541248, 0.01514633, 0.00762638, 0.00938144,\n",
       "        0.15551551, 0.01266207, 0.21243141, 0.0316776 , 0.04436075,\n",
       "        0.02878538, 0.03307165, 0.0118091 , 0.01636983, 0.00919588,\n",
       "        0.01198889, 0.00910036, 0.00337891, 0.01038835, 0.00221671,\n",
       "        0.00685395, 0.06639195, 0.05199119, 0.00959894, 0.25586168,\n",
       "        0.05966134, 0.241288  , 0.18038516, 0.11839338, 0.05967081,\n",
       "        0.14560208, 0.15129811, 0.40434374, 0.0376216 , 0.02415966,\n",
       "        0.0976579 , 0.04552481, 0.00693321, 0.01036648, 0.00764416,\n",
       "        0.02873413, 0.01502583, 0.00986116, 0.03023685, 0.03928627,\n",
       "        0.02624133, 0.02062264, 0.03651212, 0.01898244, 0.00213936,\n",
       "        0.00809376, 0.0045492 , 0.01101379, 0.00584232, 0.00659696,\n",
       "        0.01363322, 0.00486571, 0.01647104, 0.05611048, 0.02283294,\n",
       "        0.02888166, 0.01051857, 0.01541601, 0.01211182, 0.53707341,\n",
       "        0.02229207, 0.00339306, 0.00513957, 0.00872643, 0.0090936 ,\n",
       "        0.01711619, 0.0189186 , 0.00321196, 0.02328313, 0.02309832,\n",
       "        0.02428839, 0.02574641, 0.02063281, 0.01481026, 0.41234622,\n",
       "        0.50467432, 0.00721793, 0.00536146, 0.01712042, 0.00529655,\n",
       "        0.00697153, 0.00656583, 0.00162079, 0.02083677, 0.00569468,\n",
       "        0.02627831, 0.01148259, 0.02883222, 0.00794972, 0.01478421,\n",
       "        0.22913492, 0.02335152, 0.01718694, 0.01807541, 0.00731652,\n",
       "        0.01494753, 0.00697487, 0.00425385, 0.00406375, 0.05600597,\n",
       "        0.0578561 , 0.05541017, 0.05486549, 0.03641245, 0.07959659,\n",
       "        0.05044912, 0.0260273 , 0.01688656, 0.0147377 , 0.03276114,\n",
       "        0.01652109, 0.026956  , 0.05738286, 0.04977592, 0.13435107,\n",
       "        0.03968037, 0.16544341, 0.12009296, 0.07768043, 0.08475263,\n",
       "        0.11384833, 0.05843955, 0.06784914, 0.03778659, 0.01129094,\n",
       "        0.03688489, 0.00709544, 0.00789761, 0.01016561, 0.02466719,\n",
       "        0.00867252, 0.00376876, 0.02924217, 0.02207564, 0.02265702,\n",
       "        0.015436  , 0.01565469, 0.04749388, 0.04230739, 0.01687461,\n",
       "        0.00953486, 0.00877159, 0.00288115, 0.01456899, 0.01185949,\n",
       "        0.02376284, 0.0039124 , 0.04910529, 0.03331783, 0.01119423,\n",
       "        0.01974918, 0.02443971, 0.03093795, 0.03870056, 0.02130663,\n",
       "        0.0194901 , 0.00785662, 0.0037853 , 0.00348446, 0.00898133,\n",
       "        0.03083219, 0.00902263, 0.00741418, 0.00771707, 0.01816536,\n",
       "        0.00459024, 0.01385002, 0.02032296, 0.04158774, 0.04834962,\n",
       "        0.00924353, 0.02724481, 0.0096991 , 0.01234362, 0.00652103,\n",
       "        0.01846575, 0.02377134, 0.02336345, 0.0146923 , 0.00841685,\n",
       "        0.0118736 , 0.02243402, 0.0216893 , 0.00798873, 0.02409023,\n",
       "        0.0142475 , 0.01461534, 0.00799507, 0.01370565, 0.00844351,\n",
       "        0.00912033, 0.00601176, 0.02529764, 0.00777263, 0.01022977,\n",
       "        0.00242856, 0.02762656, 0.02793524, 0.02798854, 0.02350986,\n",
       "        0.01709752, 0.0216998 , 0.01049873, 0.01122127]),\n",
       " 'mean_score_time': array([0.01110568, 0.01220751, 0.01319408, 0.01376257, 0.01178417,\n",
       "        0.01264601, 0.01426992, 0.01288681, 0.01189709, 0.01398349,\n",
       "        0.0129631 , 0.03621926, 0.01732106, 0.01827364, 0.02274294,\n",
       "        0.0388164 , 0.01251864, 0.01167016, 0.0165998 , 0.06180005,\n",
       "        0.01274409, 0.01721215, 0.02076993, 0.03270683, 0.01178355,\n",
       "        0.01390409, 0.04358077, 0.01251926, 0.01819181, 0.01817741,\n",
       "        0.01812248, 0.02013392, 0.01633229, 0.01782689, 0.01610203,\n",
       "        0.01253147, 0.05331306, 0.01932068, 0.01955619, 0.01294084,\n",
       "        0.01681728, 0.01884336, 0.01749101, 0.01814613, 0.01743827,\n",
       "        0.01361384, 0.01612105, 0.01525254, 0.01286578, 0.011518  ,\n",
       "        0.016434  , 0.01407995, 0.01095695, 0.06012344, 0.01951647,\n",
       "        0.02188973, 0.02327695, 0.0220902 , 0.01457067, 0.02506652,\n",
       "        0.01525559, 0.02258496, 0.0200666 , 0.0158968 , 0.01516027,\n",
       "        0.01466479, 0.01227636, 0.01527939, 0.02444177, 0.01226215,\n",
       "        0.0168509 , 0.01516409, 0.01418953, 0.01422148, 0.0175137 ,\n",
       "        0.01602974, 0.01635103, 0.0145607 , 0.01844578, 0.01761599,\n",
       "        0.01021719, 0.0119081 , 0.01689687, 0.01162515, 0.02015309,\n",
       "        0.01241794, 0.01418104, 0.0310533 , 0.01907015, 0.02022204,\n",
       "        0.02566996, 0.01371298, 0.01351681, 0.01281261, 0.0143034 ,\n",
       "        0.0159368 , 0.03142433, 0.01132889, 0.01350985, 0.02378983,\n",
       "        0.01223397, 0.01199994, 0.0167541 , 0.01447964, 0.01377149,\n",
       "        0.01396461, 0.01236839, 0.02265711, 0.01452966, 0.01699128,\n",
       "        0.01527128, 0.01396747, 0.01271949, 0.01187773, 0.01589251,\n",
       "        0.01933789, 0.05583086, 0.0209794 , 0.01643314, 0.01373882,\n",
       "        0.01556921, 0.01422992, 0.01409268, 0.01350312, 0.01347518,\n",
       "        0.0174437 , 0.02003613, 0.01271911, 0.01080103, 0.01141582,\n",
       "        0.01236529, 0.01556039, 0.0111115 , 0.01881618, 0.01114635,\n",
       "        0.01098547, 0.01926055, 0.01525679, 0.01273661, 0.01298847,\n",
       "        0.01666136, 0.01660786, 0.01342564, 0.01321607, 0.01143274,\n",
       "        0.01201696, 0.01086345, 0.01196194, 0.01678786, 0.01259308,\n",
       "        0.01093359, 0.04973373, 0.01760526, 0.02217841, 0.0159615 ,\n",
       "        0.03098073, 0.01611533, 0.01566663, 0.01386375, 0.02216296,\n",
       "        0.0122303 , 0.0157465 , 0.01852503, 0.01252041, 0.01322837,\n",
       "        0.01160212, 0.01558795, 0.01304579, 0.01520324, 0.01234775,\n",
       "        0.01333551, 0.01423073, 0.01614933, 0.01279583, 0.02122188,\n",
       "        0.01797948, 0.01506701, 0.01306562, 0.01302109, 0.01479774,\n",
       "        0.02968373, 0.02160406, 0.01837745, 0.01742373, 0.01539092,\n",
       "        0.01659918, 0.0150578 , 0.01410131, 0.01756439, 0.01385565,\n",
       "        0.01303172, 0.01346321, 0.01178298, 0.01093106, 0.01113806,\n",
       "        0.01142812, 0.01369047, 0.01226578, 0.01307282, 0.04195495,\n",
       "        0.02324553, 0.0135035 , 0.0263679 , 0.02754259, 0.01586523,\n",
       "        0.01765323, 0.16248221, 0.03745809, 0.03978562, 0.01874285,\n",
       "        0.0295464 , 0.02079315, 0.01595101, 0.02325625, 0.01699982,\n",
       "        0.01374812, 0.01601524, 0.01711726, 0.01486378, 0.01410728,\n",
       "        0.01928248, 0.01610727, 0.02717509, 0.0179348 , 0.01384573,\n",
       "        0.0156446 , 0.0135272 , 0.01579447, 0.01675267, 0.01392956,\n",
       "        0.01407533, 0.01333504, 0.01454768, 0.01574335, 0.01994972,\n",
       "        0.01512609, 0.01614866, 0.02141647, 0.01644106, 0.0376461 ,\n",
       "        0.03201528, 0.014505  , 0.0113842 , 0.01213326, 0.0134202 ,\n",
       "        0.01628032, 0.01599917, 0.01384611, 0.01512184, 0.0160347 ,\n",
       "        0.01549439, 0.01575189, 0.01474571, 0.01383295, 0.045579  ,\n",
       "        0.01909251, 0.01751246, 0.0154645 , 0.01756291, 0.01457219,\n",
       "        0.01831765, 0.02016912, 0.01630683, 0.01655941, 0.01701732,\n",
       "        0.01284456, 0.0190743 , 0.01958222, 0.01697097, 0.01699066,\n",
       "        0.02062016, 0.01916399, 0.01701293, 0.02219653, 0.01428633,\n",
       "        0.0119957 , 0.01317048, 0.01247196, 0.01249504, 0.02330995,\n",
       "        0.02045326, 0.0501924 , 0.03877177, 0.02573972, 0.02361465,\n",
       "        0.01726213, 0.01617999, 0.01676168, 0.01630926, 0.03003993,\n",
       "        0.01759667, 0.01829476, 0.01378274, 0.02197151, 0.0405787 ,\n",
       "        0.03228436, 0.03160295, 0.01924572, 0.01877007, 0.03142352,\n",
       "        0.01692281, 0.0180964 , 0.01920805, 0.02113662, 0.0129127 ,\n",
       "        0.01465945, 0.01371527, 0.02265573, 0.01432066, 0.01621051,\n",
       "        0.01405382, 0.01402764, 0.0142271 , 0.01492624, 0.01775231,\n",
       "        0.0164629 , 0.01923156, 0.01992559, 0.0162046 , 0.01754017,\n",
       "        0.01417222, 0.01362858, 0.01322665, 0.0132246 , 0.02024131,\n",
       "        0.0131371 , 0.01509719, 0.01371584, 0.01609092, 0.01576934,\n",
       "        0.01445537, 0.01565652, 0.02030363, 0.02043839, 0.01632853,\n",
       "        0.01464548, 0.01157904, 0.0126503 , 0.01387472, 0.01374011,\n",
       "        0.01603193, 0.01398864, 0.01355052, 0.01350369, 0.01481094,\n",
       "        0.01672726, 0.01521173, 0.01544652, 0.01892843, 0.01501069,\n",
       "        0.01971564, 0.01632524, 0.01211667, 0.01784358, 0.01493626,\n",
       "        0.01671586, 0.01781917, 0.01623445, 0.01728959, 0.01511703,\n",
       "        0.01450558, 0.01536002, 0.01729674, 0.01446462, 0.01514335,\n",
       "        0.01464801, 0.01400185, 0.01979289, 0.01307249, 0.01411715,\n",
       "        0.02424941, 0.01304264, 0.01501045, 0.01662555, 0.01661034,\n",
       "        0.01507416, 0.01591229, 0.01875987, 0.01639524, 0.01503119,\n",
       "        0.0156662 , 0.01797295, 0.01443801, 0.01462426]),\n",
       " 'std_score_time': array([0.00077156, 0.00125431, 0.00236717, 0.0029651 , 0.00072771,\n",
       "        0.00305255, 0.00297782, 0.00139549, 0.000372  , 0.00235528,\n",
       "        0.00316076, 0.03093355, 0.00171384, 0.00454037, 0.01362266,\n",
       "        0.0453195 , 0.0020413 , 0.00076346, 0.0116806 , 0.0613737 ,\n",
       "        0.00211702, 0.01104228, 0.00724314, 0.0353829 , 0.00095563,\n",
       "        0.0037199 , 0.03245921, 0.0010419 , 0.00642925, 0.00494819,\n",
       "        0.00969978, 0.00796581, 0.00504004, 0.00889352, 0.00561299,\n",
       "        0.00236642, 0.05323365, 0.00578914, 0.00426025, 0.00238575,\n",
       "        0.00483549, 0.00497554, 0.00716552, 0.0052026 , 0.00589746,\n",
       "        0.00218621, 0.00453799, 0.00241173, 0.00275794, 0.00132434,\n",
       "        0.00163603, 0.00262612, 0.00054654, 0.05705501, 0.00786788,\n",
       "        0.01342542, 0.01906361, 0.00274823, 0.00233881, 0.02258209,\n",
       "        0.00254786, 0.00885479, 0.0083834 , 0.00397207, 0.00585798,\n",
       "        0.00640788, 0.0020104 , 0.00294723, 0.01814501, 0.00278245,\n",
       "        0.00796999, 0.00335261, 0.00518187, 0.00363362, 0.00155371,\n",
       "        0.00454238, 0.00371894, 0.00380264, 0.01057598, 0.0073049 ,\n",
       "        0.00041187, 0.0013677 , 0.00843315, 0.00076705, 0.0119452 ,\n",
       "        0.0007915 , 0.0028172 , 0.01700742, 0.00903704, 0.01164083,\n",
       "        0.02164541, 0.00273089, 0.00116404, 0.00102212, 0.00122612,\n",
       "        0.00230983, 0.02931608, 0.00051087, 0.00307277, 0.02504259,\n",
       "        0.00068627, 0.00079367, 0.00248154, 0.00240726, 0.00205535,\n",
       "        0.00186715, 0.0002544 , 0.0068939 , 0.00353932, 0.00601108,\n",
       "        0.00296991, 0.00148513, 0.00248206, 0.00168907, 0.00156456,\n",
       "        0.00634701, 0.05278636, 0.01653348, 0.00730289, 0.00304738,\n",
       "        0.00350566, 0.0046387 , 0.00149365, 0.00173852, 0.00155028,\n",
       "        0.0082419 , 0.00714026, 0.00061233, 0.00056767, 0.00161215,\n",
       "        0.00223676, 0.00518454, 0.00038442, 0.00949841, 0.000321  ,\n",
       "        0.00044155, 0.00367165, 0.00416919, 0.00086119, 0.00098125,\n",
       "        0.00685663, 0.00686123, 0.00129586, 0.00186754, 0.00108353,\n",
       "        0.00150364, 0.00148761, 0.00211964, 0.00817264, 0.00137961,\n",
       "        0.00022965, 0.0267238 , 0.00527579, 0.01001492, 0.00563337,\n",
       "        0.01874997, 0.00401835, 0.00332737, 0.00039758, 0.00646195,\n",
       "        0.00165439, 0.00184293, 0.00677348, 0.00166069, 0.00204961,\n",
       "        0.00071204, 0.00830588, 0.00251315, 0.00421543, 0.00048797,\n",
       "        0.00159353, 0.00285896, 0.00339838, 0.00059592, 0.00897911,\n",
       "        0.00333191, 0.00407408, 0.0022109 , 0.00231861, 0.0061018 ,\n",
       "        0.01907805, 0.01927276, 0.00775199, 0.00997197, 0.0035355 ,\n",
       "        0.00367314, 0.00450191, 0.00147682, 0.00460706, 0.0011647 ,\n",
       "        0.00037287, 0.00051406, 0.00112735, 0.00059507, 0.00053801,\n",
       "        0.00066885, 0.00222238, 0.00174   , 0.00212735, 0.06022549,\n",
       "        0.01712332, 0.00068637, 0.01612514, 0.02845541, 0.00445871,\n",
       "        0.00320431, 0.17287485, 0.02349217, 0.00835205, 0.01088848,\n",
       "        0.02524193, 0.01281068, 0.00218735, 0.01196093, 0.00442525,\n",
       "        0.00153696, 0.00194785, 0.00269669, 0.00173235, 0.00130953,\n",
       "        0.00461457, 0.00141418, 0.02461752, 0.00575443, 0.00218565,\n",
       "        0.00216501, 0.00148916, 0.00154795, 0.00603356, 0.00240284,\n",
       "        0.00189183, 0.00187833, 0.0022716 , 0.00240347, 0.00951341,\n",
       "        0.00158008, 0.00188152, 0.00647529, 0.00126838, 0.03914284,\n",
       "        0.02376812, 0.00152034, 0.00133779, 0.00155273, 0.0014799 ,\n",
       "        0.00317429, 0.004837  , 0.0019658 , 0.00240562, 0.00536939,\n",
       "        0.00484217, 0.0057035 , 0.00200378, 0.00130859, 0.05920973,\n",
       "        0.00514763, 0.00573644, 0.00539907, 0.0036333 , 0.00205976,\n",
       "        0.00350875, 0.00899333, 0.00146606, 0.00380197, 0.00641485,\n",
       "        0.00138771, 0.00607229, 0.00768961, 0.0030941 , 0.00511321,\n",
       "        0.00441817, 0.00796276, 0.00584702, 0.0099034 , 0.00172578,\n",
       "        0.00165453, 0.00054344, 0.00125888, 0.00177012, 0.00611276,\n",
       "        0.00272156, 0.06520266, 0.01312524, 0.00916589, 0.0128883 ,\n",
       "        0.00541334, 0.00141258, 0.00491485, 0.00523505, 0.01373052,\n",
       "        0.00733527, 0.00363221, 0.00176042, 0.01079373, 0.04005447,\n",
       "        0.02079453, 0.02092143, 0.00350217, 0.00590841, 0.02388663,\n",
       "        0.0016488 , 0.00381481, 0.00336715, 0.01014499, 0.00199756,\n",
       "        0.00286838, 0.00208521, 0.00908575, 0.0024261 , 0.0072041 ,\n",
       "        0.00160206, 0.00140747, 0.00107292, 0.00181531, 0.00345116,\n",
       "        0.00448684, 0.00693552, 0.00412786, 0.00171385, 0.00600002,\n",
       "        0.00323131, 0.00194961, 0.00151931, 0.0020637 , 0.01349941,\n",
       "        0.00155027, 0.00138109, 0.00159257, 0.00198418, 0.00291893,\n",
       "        0.00140017, 0.00515336, 0.00802079, 0.00605392, 0.0024113 ,\n",
       "        0.00142921, 0.00206644, 0.00141308, 0.00203662, 0.00231795,\n",
       "        0.00538508, 0.00135733, 0.00118644, 0.00146337, 0.00169763,\n",
       "        0.00310914, 0.00194545, 0.00199257, 0.00223132, 0.00088455,\n",
       "        0.00677837, 0.00259982, 0.00216616, 0.00602033, 0.0029784 ,\n",
       "        0.00499366, 0.00608396, 0.00405141, 0.0034485 , 0.00288081,\n",
       "        0.00197494, 0.00207778, 0.00313189, 0.00220741, 0.00209294,\n",
       "        0.00170349, 0.00126574, 0.00395535, 0.0025781 , 0.00192018,\n",
       "        0.01289613, 0.00322803, 0.00394736, 0.00543961, 0.00378309,\n",
       "        0.00295595, 0.00169591, 0.00442137, 0.00346978, 0.00265538,\n",
       "        0.00169866, 0.00330451, 0.00085024, 0.00256735]),\n",
       " 'param_colsample_bytree': masked_array(data=[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "                    0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "                    0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "                    0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "                    0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "                    0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "                    0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "                    0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "                    0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.6, 0.6, 0.6,\n",
       "                    0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6,\n",
       "                    0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6,\n",
       "                    0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6,\n",
       "                    0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6,\n",
       "                    0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6,\n",
       "                    0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6,\n",
       "                    0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6,\n",
       "                    0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6,\n",
       "                    0.6, 0.6, 0.6, 0.6, 0.6, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7,\n",
       "                    0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7,\n",
       "                    0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7,\n",
       "                    0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7,\n",
       "                    0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7,\n",
       "                    0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7,\n",
       "                    0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7,\n",
       "                    0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7,\n",
       "                    0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7,\n",
       "                    0.7, 0.7, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9,\n",
       "                    0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9,\n",
       "                    0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9,\n",
       "                    0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9,\n",
       "                    0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9,\n",
       "                    0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9,\n",
       "                    0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9,\n",
       "                    0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9,\n",
       "                    0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value=1e+20),\n",
       " 'param_learning_rate': masked_array(data=[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,\n",
       "                    1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "                    0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03,\n",
       "                    0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.05,\n",
       "                    0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05,\n",
       "                    0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 1.0, 1.0, 1.0, 1.0,\n",
       "                    1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,\n",
       "                    1.0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "                    0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.03, 0.03,\n",
       "                    0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03,\n",
       "                    0.03, 0.03, 0.03, 0.03, 0.03, 0.05, 0.05, 0.05, 0.05,\n",
       "                    0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05,\n",
       "                    0.05, 0.05, 0.05, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,\n",
       "                    1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.5,\n",
       "                    0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "                    0.5, 0.5, 0.5, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.03, 0.03, 0.03, 0.03,\n",
       "                    0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03,\n",
       "                    0.03, 0.03, 0.03, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05,\n",
       "                    0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05,\n",
       "                    0.05, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,\n",
       "                    1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "                    0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03,\n",
       "                    0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03,\n",
       "                    0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05,\n",
       "                    0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value=1e+20),\n",
       " 'param_n_estimators': masked_array(data=[50, 50, 50, 50, 100, 100, 100, 100, 150, 150, 150, 150,\n",
       "                    200, 200, 200, 200, 50, 50, 50, 50, 100, 100, 100, 100,\n",
       "                    150, 150, 150, 150, 200, 200, 200, 200, 50, 50, 50, 50,\n",
       "                    100, 100, 100, 100, 150, 150, 150, 150, 200, 200, 200,\n",
       "                    200, 50, 50, 50, 50, 100, 100, 100, 100, 150, 150, 150,\n",
       "                    150, 200, 200, 200, 200, 50, 50, 50, 50, 100, 100, 100,\n",
       "                    100, 150, 150, 150, 150, 200, 200, 200, 200, 50, 50,\n",
       "                    50, 50, 100, 100, 100, 100, 150, 150, 150, 150, 200,\n",
       "                    200, 200, 200, 50, 50, 50, 50, 100, 100, 100, 100, 150,\n",
       "                    150, 150, 150, 200, 200, 200, 200, 50, 50, 50, 50, 100,\n",
       "                    100, 100, 100, 150, 150, 150, 150, 200, 200, 200, 200,\n",
       "                    50, 50, 50, 50, 100, 100, 100, 100, 150, 150, 150, 150,\n",
       "                    200, 200, 200, 200, 50, 50, 50, 50, 100, 100, 100, 100,\n",
       "                    150, 150, 150, 150, 200, 200, 200, 200, 50, 50, 50, 50,\n",
       "                    100, 100, 100, 100, 150, 150, 150, 150, 200, 200, 200,\n",
       "                    200, 50, 50, 50, 50, 100, 100, 100, 100, 150, 150, 150,\n",
       "                    150, 200, 200, 200, 200, 50, 50, 50, 50, 100, 100, 100,\n",
       "                    100, 150, 150, 150, 150, 200, 200, 200, 200, 50, 50,\n",
       "                    50, 50, 100, 100, 100, 100, 150, 150, 150, 150, 200,\n",
       "                    200, 200, 200, 50, 50, 50, 50, 100, 100, 100, 100, 150,\n",
       "                    150, 150, 150, 200, 200, 200, 200, 50, 50, 50, 50, 100,\n",
       "                    100, 100, 100, 150, 150, 150, 150, 200, 200, 200, 200,\n",
       "                    50, 50, 50, 50, 100, 100, 100, 100, 150, 150, 150, 150,\n",
       "                    200, 200, 200, 200, 50, 50, 50, 50, 100, 100, 100, 100,\n",
       "                    150, 150, 150, 150, 200, 200, 200, 200, 50, 50, 50, 50,\n",
       "                    100, 100, 100, 100, 150, 150, 150, 150, 200, 200, 200,\n",
       "                    200, 50, 50, 50, 50, 100, 100, 100, 100, 150, 150, 150,\n",
       "                    150, 200, 200, 200, 200, 50, 50, 50, 50, 100, 100, 100,\n",
       "                    100, 150, 150, 150, 150, 200, 200, 200, 200, 50, 50,\n",
       "                    50, 50, 100, 100, 100, 100, 150, 150, 150, 150, 200,\n",
       "                    200, 200, 200, 50, 50, 50, 50, 100, 100, 100, 100, 150,\n",
       "                    150, 150, 150, 200, 200, 200, 200, 50, 50, 50, 50, 100,\n",
       "                    100, 100, 100, 150, 150, 150, 150, 200, 200, 200, 200],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value=999999),\n",
       " 'param_subsample': masked_array(data=[0.5, 0.6, 0.7, 0.9, 0.5, 0.6, 0.7, 0.9, 0.5, 0.6, 0.7,\n",
       "                    0.9, 0.5, 0.6, 0.7, 0.9, 0.5, 0.6, 0.7, 0.9, 0.5, 0.6,\n",
       "                    0.7, 0.9, 0.5, 0.6, 0.7, 0.9, 0.5, 0.6, 0.7, 0.9, 0.5,\n",
       "                    0.6, 0.7, 0.9, 0.5, 0.6, 0.7, 0.9, 0.5, 0.6, 0.7, 0.9,\n",
       "                    0.5, 0.6, 0.7, 0.9, 0.5, 0.6, 0.7, 0.9, 0.5, 0.6, 0.7,\n",
       "                    0.9, 0.5, 0.6, 0.7, 0.9, 0.5, 0.6, 0.7, 0.9, 0.5, 0.6,\n",
       "                    0.7, 0.9, 0.5, 0.6, 0.7, 0.9, 0.5, 0.6, 0.7, 0.9, 0.5,\n",
       "                    0.6, 0.7, 0.9, 0.5, 0.6, 0.7, 0.9, 0.5, 0.6, 0.7, 0.9,\n",
       "                    0.5, 0.6, 0.7, 0.9, 0.5, 0.6, 0.7, 0.9, 0.5, 0.6, 0.7,\n",
       "                    0.9, 0.5, 0.6, 0.7, 0.9, 0.5, 0.6, 0.7, 0.9, 0.5, 0.6,\n",
       "                    0.7, 0.9, 0.5, 0.6, 0.7, 0.9, 0.5, 0.6, 0.7, 0.9, 0.5,\n",
       "                    0.6, 0.7, 0.9, 0.5, 0.6, 0.7, 0.9, 0.5, 0.6, 0.7, 0.9,\n",
       "                    0.5, 0.6, 0.7, 0.9, 0.5, 0.6, 0.7, 0.9, 0.5, 0.6, 0.7,\n",
       "                    0.9, 0.5, 0.6, 0.7, 0.9, 0.5, 0.6, 0.7, 0.9, 0.5, 0.6,\n",
       "                    0.7, 0.9, 0.5, 0.6, 0.7, 0.9, 0.5, 0.6, 0.7, 0.9, 0.5,\n",
       "                    0.6, 0.7, 0.9, 0.5, 0.6, 0.7, 0.9, 0.5, 0.6, 0.7, 0.9,\n",
       "                    0.5, 0.6, 0.7, 0.9, 0.5, 0.6, 0.7, 0.9, 0.5, 0.6, 0.7,\n",
       "                    0.9, 0.5, 0.6, 0.7, 0.9, 0.5, 0.6, 0.7, 0.9, 0.5, 0.6,\n",
       "                    0.7, 0.9, 0.5, 0.6, 0.7, 0.9, 0.5, 0.6, 0.7, 0.9, 0.5,\n",
       "                    0.6, 0.7, 0.9, 0.5, 0.6, 0.7, 0.9, 0.5, 0.6, 0.7, 0.9,\n",
       "                    0.5, 0.6, 0.7, 0.9, 0.5, 0.6, 0.7, 0.9, 0.5, 0.6, 0.7,\n",
       "                    0.9, 0.5, 0.6, 0.7, 0.9, 0.5, 0.6, 0.7, 0.9, 0.5, 0.6,\n",
       "                    0.7, 0.9, 0.5, 0.6, 0.7, 0.9, 0.5, 0.6, 0.7, 0.9, 0.5,\n",
       "                    0.6, 0.7, 0.9, 0.5, 0.6, 0.7, 0.9, 0.5, 0.6, 0.7, 0.9,\n",
       "                    0.5, 0.6, 0.7, 0.9, 0.5, 0.6, 0.7, 0.9, 0.5, 0.6, 0.7,\n",
       "                    0.9, 0.5, 0.6, 0.7, 0.9, 0.5, 0.6, 0.7, 0.9, 0.5, 0.6,\n",
       "                    0.7, 0.9, 0.5, 0.6, 0.7, 0.9, 0.5, 0.6, 0.7, 0.9, 0.5,\n",
       "                    0.6, 0.7, 0.9, 0.5, 0.6, 0.7, 0.9, 0.5, 0.6, 0.7, 0.9,\n",
       "                    0.5, 0.6, 0.7, 0.9, 0.5, 0.6, 0.7, 0.9, 0.5, 0.6, 0.7,\n",
       "                    0.9, 0.5, 0.6, 0.7, 0.9, 0.5, 0.6, 0.7, 0.9, 0.5, 0.6,\n",
       "                    0.7, 0.9, 0.5, 0.6, 0.7, 0.9, 0.5, 0.6, 0.7, 0.9, 0.5,\n",
       "                    0.6, 0.7, 0.9, 0.5, 0.6, 0.7, 0.9, 0.5, 0.6, 0.7, 0.9,\n",
       "                    0.5, 0.6, 0.7, 0.9, 0.5, 0.6, 0.7, 0.9, 0.5, 0.6, 0.7,\n",
       "                    0.9, 0.5, 0.6, 0.7, 0.9, 0.5, 0.6, 0.7, 0.9, 0.5, 0.6,\n",
       "                    0.7, 0.9, 0.5, 0.6, 0.7, 0.9, 0.5, 0.6, 0.7, 0.9],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value=1e+20),\n",
       " 'params': [{'colsample_bytree': 0.5,\n",
       "   'learning_rate': 1.0,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 1.0,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 1.0,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 1.0,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 1.0,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 1.0,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 1.0,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 1.0,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 1.0,\n",
       "   'n_estimators': 150,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 1.0,\n",
       "   'n_estimators': 150,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 1.0,\n",
       "   'n_estimators': 150,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 1.0,\n",
       "   'n_estimators': 150,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 1.0,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 1.0,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 1.0,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 1.0,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.5,\n",
       "   'n_estimators': 150,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.5,\n",
       "   'n_estimators': 150,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.5,\n",
       "   'n_estimators': 150,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.5,\n",
       "   'n_estimators': 150,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 150,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 150,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 150,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 150,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_estimators': 150,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_estimators': 150,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_estimators': 150,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_estimators': 150,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.03,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.03,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.03,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.03,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.03,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.03,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.03,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.03,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.03,\n",
       "   'n_estimators': 150,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.03,\n",
       "   'n_estimators': 150,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.03,\n",
       "   'n_estimators': 150,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.03,\n",
       "   'n_estimators': 150,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.03,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.03,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.03,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.03,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.05,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.05,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.05,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.05,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.05,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.05,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.05,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.05,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.05,\n",
       "   'n_estimators': 150,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.05,\n",
       "   'n_estimators': 150,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.05,\n",
       "   'n_estimators': 150,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.05,\n",
       "   'n_estimators': 150,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.05,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.05,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.05,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.05,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 1.0,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 1.0,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 1.0,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 1.0,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 1.0,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 1.0,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 1.0,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 1.0,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 1.0,\n",
       "   'n_estimators': 150,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 1.0,\n",
       "   'n_estimators': 150,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 1.0,\n",
       "   'n_estimators': 150,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 1.0,\n",
       "   'n_estimators': 150,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 1.0,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 1.0,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 1.0,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 1.0,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.5,\n",
       "   'n_estimators': 150,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.5,\n",
       "   'n_estimators': 150,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.5,\n",
       "   'n_estimators': 150,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.5,\n",
       "   'n_estimators': 150,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 150,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 150,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 150,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 150,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_estimators': 150,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_estimators': 150,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_estimators': 150,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_estimators': 150,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.03,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.03,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.03,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.03,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.03,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.03,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.03,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.03,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.03,\n",
       "   'n_estimators': 150,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.03,\n",
       "   'n_estimators': 150,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.03,\n",
       "   'n_estimators': 150,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.03,\n",
       "   'n_estimators': 150,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.03,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.03,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.03,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.03,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.05,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.05,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.05,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.05,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.05,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.05,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.05,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.05,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.05,\n",
       "   'n_estimators': 150,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.05,\n",
       "   'n_estimators': 150,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.05,\n",
       "   'n_estimators': 150,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.05,\n",
       "   'n_estimators': 150,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.05,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.05,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.05,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.05,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 1.0,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 1.0,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 1.0,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 1.0,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 1.0,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 1.0,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 1.0,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 1.0,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 1.0,\n",
       "   'n_estimators': 150,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 1.0,\n",
       "   'n_estimators': 150,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 1.0,\n",
       "   'n_estimators': 150,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 1.0,\n",
       "   'n_estimators': 150,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 1.0,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 1.0,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 1.0,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 1.0,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.5,\n",
       "   'n_estimators': 150,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.5,\n",
       "   'n_estimators': 150,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.5,\n",
       "   'n_estimators': 150,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.5,\n",
       "   'n_estimators': 150,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 150,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 150,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 150,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 150,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_estimators': 150,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_estimators': 150,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_estimators': 150,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_estimators': 150,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.03,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.03,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.03,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.03,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.03,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.03,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.03,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.03,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.03,\n",
       "   'n_estimators': 150,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.03,\n",
       "   'n_estimators': 150,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.03,\n",
       "   'n_estimators': 150,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.03,\n",
       "   'n_estimators': 150,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.03,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.03,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.03,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.03,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.05,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.05,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.05,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.05,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.05,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.05,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.05,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.05,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.05,\n",
       "   'n_estimators': 150,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.05,\n",
       "   'n_estimators': 150,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.05,\n",
       "   'n_estimators': 150,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.05,\n",
       "   'n_estimators': 150,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.05,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.05,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.05,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.05,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'learning_rate': 1.0,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'learning_rate': 1.0,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'learning_rate': 1.0,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'learning_rate': 1.0,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'learning_rate': 1.0,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'learning_rate': 1.0,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'learning_rate': 1.0,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'learning_rate': 1.0,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'learning_rate': 1.0,\n",
       "   'n_estimators': 150,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'learning_rate': 1.0,\n",
       "   'n_estimators': 150,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'learning_rate': 1.0,\n",
       "   'n_estimators': 150,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'learning_rate': 1.0,\n",
       "   'n_estimators': 150,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'learning_rate': 1.0,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'learning_rate': 1.0,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'learning_rate': 1.0,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'learning_rate': 1.0,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'learning_rate': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'learning_rate': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'learning_rate': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'learning_rate': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'learning_rate': 0.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'learning_rate': 0.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'learning_rate': 0.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'learning_rate': 0.5,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'learning_rate': 0.5,\n",
       "   'n_estimators': 150,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'learning_rate': 0.5,\n",
       "   'n_estimators': 150,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'learning_rate': 0.5,\n",
       "   'n_estimators': 150,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'learning_rate': 0.5,\n",
       "   'n_estimators': 150,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'learning_rate': 0.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'learning_rate': 0.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'learning_rate': 0.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'learning_rate': 0.5,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 150,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 150,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 150,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 150,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_estimators': 150,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_estimators': 150,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_estimators': 150,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_estimators': 150,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'learning_rate': 0.03,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'learning_rate': 0.03,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'learning_rate': 0.03,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'learning_rate': 0.03,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'learning_rate': 0.03,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'learning_rate': 0.03,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'learning_rate': 0.03,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'learning_rate': 0.03,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'learning_rate': 0.03,\n",
       "   'n_estimators': 150,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'learning_rate': 0.03,\n",
       "   'n_estimators': 150,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'learning_rate': 0.03,\n",
       "   'n_estimators': 150,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'learning_rate': 0.03,\n",
       "   'n_estimators': 150,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'learning_rate': 0.03,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'learning_rate': 0.03,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'learning_rate': 0.03,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'learning_rate': 0.03,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'learning_rate': 0.05,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'learning_rate': 0.05,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'learning_rate': 0.05,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'learning_rate': 0.05,\n",
       "   'n_estimators': 50,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'learning_rate': 0.05,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'learning_rate': 0.05,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'learning_rate': 0.05,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'learning_rate': 0.05,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'learning_rate': 0.05,\n",
       "   'n_estimators': 150,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'learning_rate': 0.05,\n",
       "   'n_estimators': 150,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'learning_rate': 0.05,\n",
       "   'n_estimators': 150,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'learning_rate': 0.05,\n",
       "   'n_estimators': 150,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'learning_rate': 0.05,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'learning_rate': 0.05,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'learning_rate': 0.05,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'learning_rate': 0.05,\n",
       "   'n_estimators': 200,\n",
       "   'subsample': 0.9}],\n",
       " 'split0_test_score': array([ 0.31177509,  0.52288043,  0.50539672,  0.55701089,  0.20097429,\n",
       "         0.42831069,  0.46051514,  0.55004215,  0.07523698,  0.34636581,\n",
       "         0.44030368,  0.50144678, -0.03823566,  0.32526052,  0.43119401,\n",
       "         0.50700319,  0.71099102,  0.70869398,  0.7451359 ,  0.74752659,\n",
       "         0.69523597,  0.72083044,  0.71897078,  0.73887384,  0.67473227,\n",
       "         0.69580185,  0.69794571,  0.71959317,  0.67031479,  0.68724215,\n",
       "         0.68878257,  0.71063262,  0.7291069 ,  0.72836304,  0.7386446 ,\n",
       "         0.72449946,  0.797768  ,  0.79442281,  0.80530077,  0.79075027,\n",
       "         0.79847443,  0.79142725,  0.80401242,  0.79298365,  0.79644448,\n",
       "         0.78974116,  0.80215061,  0.79045618,  0.23978794,  0.23881602,\n",
       "         0.24130374,  0.23824626,  0.43206012,  0.43109375,  0.43190283,\n",
       "         0.43095601,  0.53722358,  0.5362975 ,  0.53634107,  0.5344311 ,\n",
       "         0.6041317 ,  0.60409164,  0.60256654,  0.59994245,  0.50890839,\n",
       "         0.50279462,  0.5133003 ,  0.50438195,  0.71204042,  0.70746887,\n",
       "         0.71056378,  0.70323884,  0.76516086,  0.76083893,  0.76280117,\n",
       "         0.75599939,  0.78892249,  0.78516865,  0.78581488,  0.77707797,\n",
       "         0.63453519,  0.63021636,  0.63956022,  0.6240617 ,  0.77550036,\n",
       "         0.77230328,  0.77752167,  0.76758158,  0.79793441,  0.79329681,\n",
       "         0.79765666,  0.79018378,  0.8054812 ,  0.80330455,  0.80573565,\n",
       "         0.79651159,  0.61095607,  0.64530838,  0.68790948,  0.70502484,\n",
       "         0.55616885,  0.6140461 ,  0.66043687,  0.68138242,  0.50287771,\n",
       "         0.59809697,  0.66638052,  0.67126358,  0.49829805,  0.58836913,\n",
       "         0.6623714 ,  0.67265129,  0.74945867,  0.76073295,  0.75176489,\n",
       "         0.76987374,  0.72591209,  0.71845067,  0.72828674,  0.740183  ,\n",
       "         0.71534729,  0.7108348 ,  0.72356987,  0.73024189,  0.70693147,\n",
       "         0.70186079,  0.71484739,  0.72722018,  0.81979156,  0.8035062 ,\n",
       "         0.8099367 ,  0.80320615,  0.83313715,  0.81587625,  0.82327384,\n",
       "         0.81597596,  0.8270579 ,  0.80666888,  0.80963266,  0.80766767,\n",
       "         0.81785774,  0.79959768,  0.80349874,  0.7974447 ,  0.32736903,\n",
       "         0.32700449,  0.3259455 ,  0.3301295 ,  0.56188262,  0.56245857,\n",
       "         0.55841863,  0.56316495,  0.66359198,  0.66054523,  0.65769142,\n",
       "         0.66198599,  0.72177517,  0.71822971,  0.71490824,  0.71644378,\n",
       "         0.63261616,  0.62797463,  0.62970614,  0.63122344,  0.80305034,\n",
       "         0.79692578,  0.7929765 ,  0.7947886 ,  0.82434464,  0.81894755,\n",
       "         0.81238329,  0.8144145 ,  0.83007395,  0.82660389,  0.81979501,\n",
       "         0.82031095,  0.74966627,  0.73561376,  0.73640615,  0.73968351,\n",
       "         0.84006953,  0.82790607,  0.82365823,  0.82473147,  0.83780736,\n",
       "         0.82812715,  0.82342964,  0.82526481,  0.83472013,  0.82585073,\n",
       "         0.82243776,  0.82222688,  0.61095607,  0.64530838,  0.68790948,\n",
       "         0.70502484,  0.55616885,  0.6140461 ,  0.66043687,  0.68138242,\n",
       "         0.50287771,  0.59809697,  0.66638052,  0.67126358,  0.49829805,\n",
       "         0.58836913,  0.6623714 ,  0.67265129,  0.74945867,  0.76073295,\n",
       "         0.75176489,  0.76987374,  0.72591209,  0.71845067,  0.72828674,\n",
       "         0.740183  ,  0.71534729,  0.7108348 ,  0.72356987,  0.73024189,\n",
       "         0.70693147,  0.70186079,  0.71484739,  0.72722018,  0.81979156,\n",
       "         0.8035062 ,  0.8099367 ,  0.80320615,  0.83313715,  0.81587625,\n",
       "         0.82327384,  0.81597596,  0.8270579 ,  0.80666888,  0.80963266,\n",
       "         0.80766767,  0.81785774,  0.79959768,  0.80349874,  0.7974447 ,\n",
       "         0.32736903,  0.32700449,  0.3259455 ,  0.3301295 ,  0.56188262,\n",
       "         0.56245857,  0.55841863,  0.56316495,  0.66359198,  0.66054523,\n",
       "         0.65769142,  0.66198599,  0.72177517,  0.71822971,  0.71490824,\n",
       "         0.71644378,  0.63261616,  0.62797463,  0.62970614,  0.63122344,\n",
       "         0.80305034,  0.79692578,  0.7929765 ,  0.7947886 ,  0.82434464,\n",
       "         0.81894755,  0.81238329,  0.8144145 ,  0.83007395,  0.82660389,\n",
       "         0.81979501,  0.82031095,  0.74966627,  0.73561376,  0.73640615,\n",
       "         0.73968351,  0.84006953,  0.82790607,  0.82365823,  0.82473147,\n",
       "         0.83780736,  0.82812715,  0.82342964,  0.82526481,  0.83472013,\n",
       "         0.82585073,  0.82243776,  0.82222688,  0.5409143 ,  0.65816325,\n",
       "         0.69581759,  0.75430512,  0.49494421,  0.56804991,  0.65533412,\n",
       "         0.72628593,  0.47295803,  0.5614385 ,  0.66028273,  0.71450543,\n",
       "         0.47154593,  0.53725588,  0.66453278,  0.68962717,  0.75285745,\n",
       "         0.7830143 ,  0.77960336,  0.78697205,  0.74380314,  0.74988967,\n",
       "         0.75271195,  0.76894093,  0.74026811,  0.75509763,  0.75071025,\n",
       "         0.76358783,  0.7368089 ,  0.74810719,  0.74819052,  0.7564159 ,\n",
       "         0.86101758,  0.86304355,  0.85556579,  0.86083156,  0.84153748,\n",
       "         0.84338152,  0.8374514 ,  0.84240079,  0.82095867,  0.82894278,\n",
       "         0.82295316,  0.82863814,  0.81321663,  0.81898272,  0.81427687,\n",
       "         0.82024968,  0.45430744,  0.4507218 ,  0.4519999 ,  0.45291394,\n",
       "         0.6969586 ,  0.69483781,  0.69329447,  0.69333148,  0.78769886,\n",
       "         0.78650862,  0.78312945,  0.78259861,  0.82764727,  0.82601744,\n",
       "         0.82384503,  0.82123786,  0.77067137,  0.76840615,  0.77090204,\n",
       "         0.76966387,  0.86366332,  0.85991788,  0.8586123 ,  0.85827869,\n",
       "         0.86772311,  0.86167365,  0.86109954,  0.86038399,  0.86418545,\n",
       "         0.85636878,  0.8571465 ,  0.85541141,  0.84784532,  0.84301358,\n",
       "         0.83898056,  0.8432101 ,  0.8652426 ,  0.86106849,  0.85744303,\n",
       "         0.86020553,  0.85579139,  0.85058361,  0.84828645,  0.85133857,\n",
       "         0.84700805,  0.84268409,  0.83918387,  0.84311557]),\n",
       " 'split1_test_score': array([ 0.10299414,  0.36766386,  0.36635476,  0.53946877,  0.09046876,\n",
       "         0.33069992,  0.30658537,  0.45661616, -0.04706156,  0.23453349,\n",
       "         0.23314738,  0.4400385 , -0.07923079,  0.22281265,  0.22649449,\n",
       "         0.43447667,  0.59377694,  0.64959538,  0.64556301,  0.66038787,\n",
       "         0.60322618,  0.62927938,  0.63396406,  0.64385438,  0.59123349,\n",
       "         0.62559187,  0.60990447,  0.62275338,  0.57026207,  0.5999409 ,\n",
       "         0.59237045,  0.60439646,  0.70202649,  0.70914733,  0.71209979,\n",
       "         0.71120709,  0.76581311,  0.76941013,  0.76820236,  0.76447767,\n",
       "         0.76485378,  0.76678133,  0.76721823,  0.7648111 ,  0.76452953,\n",
       "         0.76377034,  0.76808637,  0.76514387,  0.23005867,  0.23028731,\n",
       "         0.23052633,  0.22896457,  0.42486089,  0.42098802,  0.42437297,\n",
       "         0.42130411,  0.5346427 ,  0.5296638 ,  0.53281784,  0.52911085,\n",
       "         0.60227609,  0.59884691,  0.60053796,  0.59609383,  0.51246059,\n",
       "         0.51668859,  0.51597703,  0.50940192,  0.6983285 ,  0.70097423,\n",
       "         0.70195788,  0.69353002,  0.74868292,  0.75009108,  0.74986768,\n",
       "         0.74093944,  0.7667886 ,  0.76834911,  0.7661649 ,  0.75780779,\n",
       "         0.6312415 ,  0.63352847,  0.63307273,  0.63083035,  0.75081009,\n",
       "         0.75268531,  0.75217223,  0.74938399,  0.7696321 ,  0.77447486,\n",
       "         0.76853228,  0.76509321,  0.7751776 ,  0.77914959,  0.77623487,\n",
       "         0.77448583,  0.49815691,  0.55375564,  0.55555594,  0.6485942 ,\n",
       "         0.42925704,  0.47953987,  0.49639362,  0.63740838,  0.40869862,\n",
       "         0.43578541,  0.49056786,  0.62259465,  0.38233596,  0.41031504,\n",
       "         0.4710744 ,  0.6140666 ,  0.70588434,  0.74598801,  0.72669971,\n",
       "         0.7648989 ,  0.68102598,  0.7081793 ,  0.6677556 ,  0.73221391,\n",
       "         0.63523376,  0.69557214,  0.64919311,  0.71877265,  0.60643834,\n",
       "         0.68820965,  0.63707173,  0.7073617 ,  0.77966988,  0.77523094,\n",
       "         0.77748376,  0.78434861,  0.79790771,  0.79555947,  0.7895754 ,\n",
       "         0.8029601 ,  0.78349006,  0.78294921,  0.77637357,  0.79318225,\n",
       "         0.76856977,  0.7718997 ,  0.76855469,  0.78289109,  0.31660753,\n",
       "         0.31961036,  0.3191542 ,  0.32370549,  0.54521227,  0.54665679,\n",
       "         0.54868245,  0.5542413 ,  0.65002322,  0.64853799,  0.65171456,\n",
       "         0.65721655,  0.70641339,  0.70468986,  0.708956  ,  0.71277869,\n",
       "         0.62397254,  0.62602437,  0.62387723,  0.63127017,  0.77862722,\n",
       "         0.77895647,  0.77539796,  0.78385389,  0.797153  ,  0.79649115,\n",
       "         0.79655218,  0.80076706,  0.80384094,  0.8026008 ,  0.80372614,\n",
       "         0.80861419,  0.72734529,  0.73084164,  0.72602606,  0.73490763,\n",
       "         0.80391908,  0.80318016,  0.79986298,  0.8112222 ,  0.80115688,\n",
       "         0.79961514,  0.8000989 ,  0.80932146,  0.79519129,  0.79523838,\n",
       "         0.79902428,  0.80860126,  0.49815691,  0.55375564,  0.55555594,\n",
       "         0.6485942 ,  0.42925704,  0.47953987,  0.49639362,  0.63740838,\n",
       "         0.40869862,  0.43578541,  0.49056786,  0.62259465,  0.38233596,\n",
       "         0.41031504,  0.4710744 ,  0.6140666 ,  0.70588434,  0.74598801,\n",
       "         0.72669971,  0.7648989 ,  0.68102598,  0.7081793 ,  0.6677556 ,\n",
       "         0.73221391,  0.63523376,  0.69557214,  0.64919311,  0.71877265,\n",
       "         0.60643834,  0.68820965,  0.63707173,  0.7073617 ,  0.77966988,\n",
       "         0.77523094,  0.77748376,  0.78434861,  0.79790771,  0.79555947,\n",
       "         0.7895754 ,  0.8029601 ,  0.78349006,  0.78294921,  0.77637357,\n",
       "         0.79318225,  0.76856977,  0.7718997 ,  0.76855469,  0.78289109,\n",
       "         0.31660753,  0.31961036,  0.3191542 ,  0.32370549,  0.54521227,\n",
       "         0.54665679,  0.54868245,  0.5542413 ,  0.65002322,  0.64853799,\n",
       "         0.65171456,  0.65721655,  0.70641339,  0.70468986,  0.708956  ,\n",
       "         0.71277869,  0.62397254,  0.62602437,  0.62387723,  0.63127017,\n",
       "         0.77862722,  0.77895647,  0.77539796,  0.78385389,  0.797153  ,\n",
       "         0.79649115,  0.79655218,  0.80076706,  0.80384094,  0.8026008 ,\n",
       "         0.80372614,  0.80861419,  0.72734529,  0.73084164,  0.72602606,\n",
       "         0.73490763,  0.80391908,  0.80318016,  0.79986298,  0.8112222 ,\n",
       "         0.80115688,  0.79961514,  0.8000989 ,  0.80932146,  0.79519129,\n",
       "         0.79523838,  0.79902428,  0.80860126,  0.47721517,  0.5598408 ,\n",
       "         0.58698767,  0.68632394,  0.40720314,  0.52043378,  0.56062824,\n",
       "         0.67575914,  0.35345823,  0.51133573,  0.54847467,  0.66932869,\n",
       "         0.30884963,  0.49204147,  0.52569783,  0.66693163,  0.707376  ,\n",
       "         0.76839375,  0.73870349,  0.77209592,  0.67484474,  0.73347092,\n",
       "         0.7074368 ,  0.75409305,  0.66091603,  0.7101748 ,  0.7002176 ,\n",
       "         0.74595308,  0.65643358,  0.70126927,  0.69210398,  0.7431128 ,\n",
       "         0.82650405,  0.8375535 ,  0.83083987,  0.83627063,  0.81593257,\n",
       "         0.81919926,  0.81391329,  0.82205832,  0.80445939,  0.79566598,\n",
       "         0.79396516,  0.80873454,  0.78843135,  0.7890808 ,  0.78330576,\n",
       "         0.7974987 ,  0.42399943,  0.42571622,  0.42774755,  0.42999452,\n",
       "         0.65842986,  0.65819031,  0.66110682,  0.66343546,  0.75016737,\n",
       "         0.75186712,  0.75359154,  0.75446123,  0.79297346,  0.79426134,\n",
       "         0.79562336,  0.79562771,  0.74036062,  0.74198157,  0.74454689,\n",
       "         0.74583721,  0.83026779,  0.83052468,  0.83139014,  0.83206892,\n",
       "         0.83690232,  0.83787924,  0.83561277,  0.83726478,  0.83294094,\n",
       "         0.83701515,  0.83318907,  0.83519554,  0.81185716,  0.81584573,\n",
       "         0.8178212 ,  0.81521749,  0.83412671,  0.83628744,  0.83897394,\n",
       "         0.83677834,  0.82658261,  0.82382464,  0.83131433,  0.82837856,\n",
       "         0.81691033,  0.81822705,  0.82278401,  0.8201766 ]),\n",
       " 'split2_test_score': array([ 0.09554058,  0.2353375 ,  0.42218739,  0.48840564,  0.15427613,\n",
       "         0.1812883 ,  0.38101119,  0.45786595,  0.08026588,  0.12269688,\n",
       "         0.34200931,  0.42812657, -0.00432074,  0.10350114,  0.3282721 ,\n",
       "         0.42423284,  0.59175026,  0.61704338,  0.67717302,  0.68705446,\n",
       "         0.58792686,  0.60981047,  0.66276085,  0.68028367,  0.57861578,\n",
       "         0.61440909,  0.64599168,  0.67425442,  0.5664854 ,  0.60538745,\n",
       "         0.62956488,  0.66709995,  0.71583116,  0.71264482,  0.71653748,\n",
       "         0.70880425,  0.76798409,  0.75939244,  0.7638467 ,  0.76020545,\n",
       "         0.77422643,  0.76451927,  0.76388192,  0.76376522,  0.76972693,\n",
       "         0.76217824,  0.76286608,  0.76152205,  0.24588484,  0.24700886,\n",
       "         0.24904817,  0.24594736,  0.43377584,  0.433667  ,  0.43612146,\n",
       "         0.43227893,  0.53666049,  0.53723574,  0.53906053,  0.53282696,\n",
       "         0.60184324,  0.60027885,  0.60252559,  0.59602362,  0.51402003,\n",
       "         0.51800632,  0.51802385,  0.51008672,  0.70006573,  0.69790924,\n",
       "         0.69672918,  0.68742627,  0.74714392,  0.74630755,  0.74430752,\n",
       "         0.7357251 ,  0.76437664,  0.7619046 ,  0.76143837,  0.75351721,\n",
       "         0.63399267,  0.63301718,  0.63189107,  0.62519097,  0.75440782,\n",
       "         0.75057292,  0.74908149,  0.74220574,  0.77298009,  0.76898825,\n",
       "         0.76682121,  0.75862521,  0.77683544,  0.77193707,  0.77370638,\n",
       "         0.7659483 ,  0.47726774,  0.56276917,  0.60388565,  0.68928671,\n",
       "         0.4442808 ,  0.53423399,  0.57917976,  0.67738652,  0.41585666,\n",
       "         0.54307342,  0.57887495,  0.67900544,  0.39422452,  0.53863955,\n",
       "         0.57604551,  0.67888212,  0.73981613,  0.72190189,  0.75217819,\n",
       "         0.72497594,  0.71715534,  0.69874275,  0.72140455,  0.71026385,\n",
       "         0.7090345 ,  0.68558532,  0.71325386,  0.70564413,  0.70396233,\n",
       "         0.68254626,  0.70909327,  0.70327109,  0.78000283,  0.78662091,\n",
       "         0.78222036,  0.77387142,  0.78286111,  0.79425979,  0.78636515,\n",
       "         0.78368807,  0.77212906,  0.7879492 ,  0.776016  ,  0.77245855,\n",
       "         0.77001727,  0.78478122,  0.77239561,  0.76771939,  0.33258945,\n",
       "         0.33214295,  0.33302015,  0.32902128,  0.55563879,  0.55210102,\n",
       "         0.55496097,  0.55012798,  0.65182382,  0.64921004,  0.65136129,\n",
       "         0.64463115,  0.70534396,  0.70168018,  0.70383656,  0.69536245,\n",
       "         0.62896943,  0.62908149,  0.63111413,  0.62310469,  0.77096617,\n",
       "         0.77207428,  0.77433234,  0.76774496,  0.78821355,  0.79101694,\n",
       "         0.79001403,  0.78536987,  0.79306859,  0.79628015,  0.79637021,\n",
       "         0.78971511,  0.7259872 ,  0.72879899,  0.72646689,  0.71821809,\n",
       "         0.78741658,  0.79357791,  0.79281729,  0.78836137,  0.78420758,\n",
       "         0.79136497,  0.79038823,  0.78736997,  0.78125119,  0.7910381 ,\n",
       "         0.78808236,  0.78407192,  0.47726774,  0.56276917,  0.60388565,\n",
       "         0.68928671,  0.4442808 ,  0.53423399,  0.57917976,  0.67738652,\n",
       "         0.41585666,  0.54307342,  0.57887495,  0.67900544,  0.39422452,\n",
       "         0.53863955,  0.57604551,  0.67888212,  0.73981613,  0.72190189,\n",
       "         0.75217819,  0.72497594,  0.71715534,  0.69874275,  0.72140455,\n",
       "         0.71026385,  0.7090345 ,  0.68558532,  0.71325386,  0.70564413,\n",
       "         0.70396233,  0.68254626,  0.70909327,  0.70327109,  0.78000283,\n",
       "         0.78662091,  0.78222036,  0.77387142,  0.78286111,  0.79425979,\n",
       "         0.78636515,  0.78368807,  0.77212906,  0.7879492 ,  0.776016  ,\n",
       "         0.77245855,  0.77001727,  0.78478122,  0.77239561,  0.76771939,\n",
       "         0.33258945,  0.33214295,  0.33302015,  0.32902128,  0.55563879,\n",
       "         0.55210102,  0.55496097,  0.55012798,  0.65182382,  0.64921004,\n",
       "         0.65136129,  0.64463115,  0.70534396,  0.70168018,  0.70383656,\n",
       "         0.69536245,  0.62896943,  0.62908149,  0.63111413,  0.62310469,\n",
       "         0.77096617,  0.77207428,  0.77433234,  0.76774496,  0.78821355,\n",
       "         0.79101694,  0.79001403,  0.78536987,  0.79306859,  0.79628015,\n",
       "         0.79637021,  0.78971511,  0.7259872 ,  0.72879899,  0.72646689,\n",
       "         0.71821809,  0.78741658,  0.79357791,  0.79281729,  0.78836137,\n",
       "         0.78420758,  0.79136497,  0.79038823,  0.78736997,  0.78125119,\n",
       "         0.7910381 ,  0.78808236,  0.78407192,  0.54765272,  0.60403526,\n",
       "         0.67071748,  0.73056436,  0.5086776 ,  0.60414231,  0.66303754,\n",
       "         0.7308206 ,  0.50505161,  0.61049104,  0.66378224,  0.73137218,\n",
       "         0.50947917,  0.61083806,  0.66378146,  0.7314716 ,  0.74746978,\n",
       "         0.75446433,  0.75868893,  0.77591133,  0.72754979,  0.74587291,\n",
       "         0.74595022,  0.76574683,  0.72715425,  0.74728143,  0.74340099,\n",
       "         0.76455218,  0.72619236,  0.74456275,  0.74184614,  0.76422608,\n",
       "         0.81247616,  0.81169057,  0.81892371,  0.81449598,  0.79857975,\n",
       "         0.79704046,  0.80638587,  0.80242282,  0.78620338,  0.786708  ,\n",
       "         0.79675919,  0.79960448,  0.78183931,  0.78297961,  0.79301441,\n",
       "         0.79599595,  0.43922949,  0.44123912,  0.4421646 ,  0.44135714,\n",
       "         0.66882944,  0.66997081,  0.67047822,  0.67066574,  0.75497651,\n",
       "         0.75465655,  0.75582701,  0.75620413,  0.79111958,  0.78987181,\n",
       "         0.79184687,  0.79158378,  0.74036229,  0.74514306,  0.74856097,\n",
       "         0.74508631,  0.8172667 ,  0.82145315,  0.82206261,  0.81958044,\n",
       "         0.81828368,  0.82153916,  0.82014406,  0.81756234,  0.81425208,\n",
       "         0.81599802,  0.81744105,  0.81392401,  0.80433428,  0.81120455,\n",
       "         0.80984473,  0.80723941,  0.81650484,  0.81777596,  0.81631994,\n",
       "         0.81561601,  0.81092995,  0.81171834,  0.81008035,  0.81064808,\n",
       "         0.80460316,  0.80744427,  0.80586755,  0.80603862]),\n",
       " 'split3_test_score': array([0.41141069, 0.48798156, 0.43317336, 0.57300758, 0.43505043,\n",
       "        0.4418087 , 0.43938321, 0.53672159, 0.3784216 , 0.400397  ,\n",
       "        0.40336531, 0.51686448, 0.35860497, 0.40300453, 0.369609  ,\n",
       "        0.51577985, 0.6868819 , 0.7503258 , 0.70636606, 0.7086553 ,\n",
       "        0.670398  , 0.74638635, 0.70234144, 0.71727782, 0.67723238,\n",
       "        0.725003  , 0.69256556, 0.69902337, 0.67480242, 0.72029161,\n",
       "        0.69423139, 0.6939258 , 0.73211771, 0.71995223, 0.72221249,\n",
       "        0.72949803, 0.79833972, 0.79163277, 0.79515028, 0.79811144,\n",
       "        0.80765057, 0.7944808 , 0.80150962, 0.80489284, 0.81135488,\n",
       "        0.79751325, 0.80585623, 0.80770254, 0.2393328 , 0.24027497,\n",
       "        0.24176228, 0.24219382, 0.42859215, 0.42655635, 0.42913115,\n",
       "        0.42945784, 0.53254497, 0.52935755, 0.53195429, 0.53258437,\n",
       "        0.59832931, 0.59607041, 0.59572411, 0.59684777, 0.50680745,\n",
       "        0.50910807, 0.51133037, 0.51050824, 0.69759607, 0.69852722,\n",
       "        0.70428574, 0.69855118, 0.74949777, 0.74982071, 0.75359797,\n",
       "        0.74669683, 0.7736007 , 0.77573097, 0.7766583 , 0.76918405,\n",
       "        0.63427413, 0.62872016, 0.63236165, 0.63474572, 0.76273143,\n",
       "        0.76645249, 0.76404154, 0.76395154, 0.78431022, 0.7874859 ,\n",
       "        0.78832972, 0.78603959, 0.79552817, 0.79950643, 0.79914188,\n",
       "        0.79594308, 0.52805102, 0.65227187, 0.70806998, 0.73599005,\n",
       "        0.44602531, 0.61438632, 0.69784456, 0.7260614 , 0.41517568,\n",
       "        0.59092963, 0.68280053, 0.72109616, 0.40610957, 0.57547218,\n",
       "        0.6764046 , 0.71520096, 0.77597666, 0.75155294, 0.77021164,\n",
       "        0.76870716, 0.75176954, 0.74105978, 0.75479126, 0.74901426,\n",
       "        0.74033749, 0.7221967 , 0.74362135, 0.74015993, 0.7346791 ,\n",
       "        0.72171623, 0.74364161, 0.73975635, 0.79494584, 0.7927959 ,\n",
       "        0.79541856, 0.79898471, 0.8199321 , 0.81679976, 0.82352126,\n",
       "        0.82590187, 0.81612241, 0.81180263, 0.81639987, 0.82025588,\n",
       "        0.81377202, 0.80831563, 0.81323332, 0.81759322, 0.3225593 ,\n",
       "        0.32653809, 0.32750356, 0.32693833, 0.54806304, 0.55009341,\n",
       "        0.55172223, 0.55017245, 0.64479744, 0.64505231, 0.64766157,\n",
       "        0.64447606, 0.70319349, 0.70198095, 0.70253956, 0.70013797,\n",
       "        0.61652207, 0.62317967, 0.6251902 , 0.62197363, 0.77821195,\n",
       "        0.78411001, 0.78667223, 0.78095382, 0.80328208, 0.80546099,\n",
       "        0.8083815 , 0.80287886, 0.81569004, 0.81624985, 0.81847137,\n",
       "        0.81462371, 0.72575521, 0.73044693, 0.73071504, 0.72690749,\n",
       "        0.81706518, 0.81750375, 0.81927836, 0.81582451, 0.82391489,\n",
       "        0.81985462, 0.82333863, 0.82065821, 0.82640731, 0.82381248,\n",
       "        0.82504487, 0.8242619 , 0.52805102, 0.65227187, 0.70806998,\n",
       "        0.73599005, 0.44602531, 0.61438632, 0.69784456, 0.7260614 ,\n",
       "        0.41517568, 0.59092963, 0.68280053, 0.72109616, 0.40610957,\n",
       "        0.57547218, 0.6764046 , 0.71520096, 0.77597666, 0.75155294,\n",
       "        0.77021164, 0.76870716, 0.75176954, 0.74105978, 0.75479126,\n",
       "        0.74901426, 0.74033749, 0.7221967 , 0.74362135, 0.74015993,\n",
       "        0.7346791 , 0.72171623, 0.74364161, 0.73975635, 0.79494584,\n",
       "        0.7927959 , 0.79541856, 0.79898471, 0.8199321 , 0.81679976,\n",
       "        0.82352126, 0.82590187, 0.81612241, 0.81180263, 0.81639987,\n",
       "        0.82025588, 0.81377202, 0.80831563, 0.81323332, 0.81759322,\n",
       "        0.3225593 , 0.32653809, 0.32750356, 0.32693833, 0.54806304,\n",
       "        0.55009341, 0.55172223, 0.55017245, 0.64479744, 0.64505231,\n",
       "        0.64766157, 0.64447606, 0.70319349, 0.70198095, 0.70253956,\n",
       "        0.70013797, 0.61652207, 0.62317967, 0.6251902 , 0.62197363,\n",
       "        0.77821195, 0.78411001, 0.78667223, 0.78095382, 0.80328208,\n",
       "        0.80546099, 0.8083815 , 0.80287886, 0.81569004, 0.81624985,\n",
       "        0.81847137, 0.81462371, 0.72575521, 0.73044693, 0.73071504,\n",
       "        0.72690749, 0.81706518, 0.81750375, 0.81927836, 0.81582451,\n",
       "        0.82391489, 0.81985462, 0.82333863, 0.82065821, 0.82640731,\n",
       "        0.82381248, 0.82504487, 0.8242619 , 0.60324335, 0.66991764,\n",
       "        0.6895932 , 0.77492094, 0.54117596, 0.60864401, 0.67345613,\n",
       "        0.77209878, 0.52671587, 0.59441006, 0.67081499, 0.77201355,\n",
       "        0.51852727, 0.62608099, 0.6703285 , 0.77125251, 0.76597804,\n",
       "        0.77513963, 0.7953155 , 0.80597222, 0.74369848, 0.75695419,\n",
       "        0.78421509, 0.7965166 , 0.73295629, 0.75291508, 0.775397  ,\n",
       "        0.7943238 , 0.72281122, 0.75534338, 0.77762121, 0.7907663 ,\n",
       "        0.85024905, 0.84370983, 0.83925641, 0.84788942, 0.83976644,\n",
       "        0.83196151, 0.83772087, 0.84144646, 0.83240354, 0.82261497,\n",
       "        0.83120728, 0.83530992, 0.82981145, 0.81885868, 0.82800788,\n",
       "        0.83050561, 0.43032557, 0.42866373, 0.4300071 , 0.42836469,\n",
       "        0.6624999 , 0.66039288, 0.66281712, 0.66015196, 0.7531262 ,\n",
       "        0.7505396 , 0.75251973, 0.74989963, 0.79655451, 0.79442006,\n",
       "        0.79572332, 0.79332805, 0.74200618, 0.74076831, 0.73817581,\n",
       "        0.73441541, 0.84071487, 0.83919418, 0.83823079, 0.83748472,\n",
       "        0.85121059, 0.8481428 , 0.84674412, 0.84635437, 0.85046655,\n",
       "        0.84692943, 0.84726322, 0.84710467, 0.82341015, 0.81914079,\n",
       "        0.81909585, 0.81426603, 0.8549071 , 0.84927529, 0.85044497,\n",
       "        0.84701264, 0.85283422, 0.84691274, 0.84788895, 0.84539831,\n",
       "        0.84829068, 0.84345233, 0.84470546, 0.8416608 ]),\n",
       " 'split4_test_score': array([0.39355779, 0.45382816, 0.51732409, 0.54098785, 0.27328861,\n",
       "        0.35430723, 0.49869931, 0.49225974, 0.22774178, 0.30812776,\n",
       "        0.46768856, 0.48777169, 0.24357748, 0.26646882, 0.44497943,\n",
       "        0.47706795, 0.68423027, 0.68705165, 0.67060465, 0.64306545,\n",
       "        0.70137513, 0.70837426, 0.70488727, 0.63867545, 0.69573462,\n",
       "        0.6858815 , 0.68639731, 0.62477237, 0.69502974, 0.665766  ,\n",
       "        0.6806705 , 0.62517071, 0.7067554 , 0.69961423, 0.70147431,\n",
       "        0.70002437, 0.75955296, 0.7584148 , 0.75730217, 0.75734216,\n",
       "        0.75934726, 0.75736928, 0.75131482, 0.75407094, 0.75741321,\n",
       "        0.75214231, 0.75000793, 0.7503351 , 0.21630812, 0.22037011,\n",
       "        0.21837902, 0.22125298, 0.40107483, 0.40670961, 0.40253317,\n",
       "        0.40496147, 0.50504214, 0.50886011, 0.50603044, 0.50750571,\n",
       "        0.57110131, 0.57352549, 0.57067794, 0.57306093, 0.47933388,\n",
       "        0.48569804, 0.48631889, 0.48330367, 0.67005658, 0.67586589,\n",
       "        0.67492151, 0.66821134, 0.723629  , 0.72986841, 0.72935152,\n",
       "        0.7220121 , 0.74282944, 0.75047415, 0.74872875, 0.74160492,\n",
       "        0.6059891 , 0.60865915, 0.60860765, 0.60502815, 0.73546827,\n",
       "        0.73787916, 0.73690552, 0.7321614 , 0.7565347 , 0.75888801,\n",
       "        0.75888634, 0.75379521, 0.76176214, 0.76295578, 0.76397777,\n",
       "        0.75787342, 0.58492202, 0.6072377 , 0.63677734, 0.66238356,\n",
       "        0.5671277 , 0.58002055, 0.61214089, 0.6375978 , 0.54941314,\n",
       "        0.57378477, 0.60659003, 0.63890153, 0.52968967, 0.55756795,\n",
       "        0.59722817, 0.63643324, 0.71211451, 0.70638245, 0.71976411,\n",
       "        0.74538076, 0.68675303, 0.67597675, 0.69415545, 0.73439533,\n",
       "        0.67484921, 0.66986156, 0.69513434, 0.72570235, 0.66661966,\n",
       "        0.66264868, 0.69011521, 0.72407293, 0.7631737 , 0.75698209,\n",
       "        0.75406414, 0.75121641, 0.77618015, 0.77252924, 0.7687341 ,\n",
       "        0.76864392, 0.76770329, 0.75706029, 0.7568804 , 0.7587536 ,\n",
       "        0.761482  , 0.75159717, 0.75229216, 0.75296396, 0.29842538,\n",
       "        0.3030116 , 0.30112571, 0.30272162, 0.51642776, 0.5197283 ,\n",
       "        0.51872349, 0.51854873, 0.61352026, 0.61593878, 0.61432499,\n",
       "        0.61402082, 0.66733098, 0.6706723 , 0.66798103, 0.66780615,\n",
       "        0.59510738, 0.59846467, 0.59482592, 0.5912841 , 0.74805957,\n",
       "        0.74682212, 0.74307573, 0.73861456, 0.77145964, 0.76917791,\n",
       "        0.76822406, 0.76045799, 0.7774514 , 0.7754029 , 0.7752279 ,\n",
       "        0.76666069, 0.69546449, 0.70053768, 0.69593894, 0.69393778,\n",
       "        0.77521855, 0.77318281, 0.77129447, 0.76608789, 0.77717453,\n",
       "        0.77287245, 0.77306098, 0.76680082, 0.77438259, 0.76974499,\n",
       "        0.77097768, 0.7669434 , 0.58492202, 0.6072377 , 0.63677734,\n",
       "        0.66238356, 0.5671277 , 0.58002055, 0.61214089, 0.6375978 ,\n",
       "        0.54941314, 0.57378477, 0.60659003, 0.63890153, 0.52968967,\n",
       "        0.55756795, 0.59722817, 0.63643324, 0.71211451, 0.70638245,\n",
       "        0.71976411, 0.74538076, 0.68675303, 0.67597675, 0.69415545,\n",
       "        0.73439533, 0.67484921, 0.66986156, 0.69513434, 0.72570235,\n",
       "        0.66661966, 0.66264868, 0.69011521, 0.72407293, 0.7631737 ,\n",
       "        0.75698209, 0.75406414, 0.75121641, 0.77618015, 0.77252924,\n",
       "        0.7687341 , 0.76864392, 0.76770329, 0.75706029, 0.7568804 ,\n",
       "        0.7587536 , 0.761482  , 0.75159717, 0.75229216, 0.75296396,\n",
       "        0.29842538, 0.3030116 , 0.30112571, 0.30272162, 0.51642776,\n",
       "        0.5197283 , 0.51872349, 0.51854873, 0.61352026, 0.61593878,\n",
       "        0.61432499, 0.61402082, 0.66733098, 0.6706723 , 0.66798103,\n",
       "        0.66780615, 0.59510738, 0.59846467, 0.59482592, 0.5912841 ,\n",
       "        0.74805957, 0.74682212, 0.74307573, 0.73861456, 0.77145964,\n",
       "        0.76917791, 0.76822406, 0.76045799, 0.7774514 , 0.7754029 ,\n",
       "        0.7752279 , 0.76666069, 0.69546449, 0.70053768, 0.69593894,\n",
       "        0.69393778, 0.77521855, 0.77318281, 0.77129447, 0.76608789,\n",
       "        0.77717453, 0.77287245, 0.77306098, 0.76680082, 0.77438259,\n",
       "        0.76974499, 0.77097768, 0.7669434 , 0.53342634, 0.63502455,\n",
       "        0.65764999, 0.69220066, 0.49447978, 0.62157559, 0.6484198 ,\n",
       "        0.68624157, 0.48096961, 0.61407274, 0.65246624, 0.68467593,\n",
       "        0.46882433, 0.6164763 , 0.64972627, 0.68498826, 0.71195745,\n",
       "        0.71837521, 0.73296481, 0.72094238, 0.69990349, 0.69984376,\n",
       "        0.72174442, 0.70670933, 0.69035816, 0.69488567, 0.72063446,\n",
       "        0.70576262, 0.68514383, 0.6949991 , 0.71973813, 0.70423949,\n",
       "        0.77911919, 0.78795898, 0.78506833, 0.77579832, 0.76054299,\n",
       "        0.7742278 , 0.77063596, 0.76629448, 0.74986529, 0.75705481,\n",
       "        0.75657272, 0.75492382, 0.74418271, 0.75302303, 0.74860573,\n",
       "        0.75011885, 0.40351224, 0.40538007, 0.40375525, 0.40465653,\n",
       "        0.624641  , 0.62470782, 0.62393087, 0.62327164, 0.70986646,\n",
       "        0.70921016, 0.70904303, 0.7083751 , 0.74815273, 0.74716949,\n",
       "        0.7473709 , 0.74642229, 0.69800675, 0.70277947, 0.69764608,\n",
       "        0.69769537, 0.7824654 , 0.78303409, 0.78056824, 0.77679509,\n",
       "        0.78634673, 0.78546661, 0.78486794, 0.78223151, 0.78210056,\n",
       "        0.78186476, 0.78130263, 0.77994466, 0.7699315 , 0.7710101 ,\n",
       "        0.76649606, 0.76904213, 0.78613842, 0.7881301 , 0.78371865,\n",
       "        0.78637254, 0.77707732, 0.77872318, 0.77596843, 0.78066492,\n",
       "        0.76846015, 0.77178788, 0.7691738 , 0.77431726]),\n",
       " 'mean_test_score': array([0.26305566, 0.4135383 , 0.44888726, 0.53977615, 0.23081164,\n",
       "        0.34728297, 0.41723884, 0.49870112, 0.14292094, 0.28242419,\n",
       "        0.37730285, 0.47484961, 0.09607905, 0.26420953, 0.36010981,\n",
       "        0.4717121 , 0.65352608, 0.68254204, 0.68896853, 0.68933793,\n",
       "        0.65163243, 0.68293618, 0.68458488, 0.68379303, 0.64350971,\n",
       "        0.66933746, 0.66656095, 0.66807934, 0.63537889, 0.65572562,\n",
       "        0.65712396, 0.66024511, 0.71716753, 0.71394433, 0.71819373,\n",
       "        0.71480664, 0.77789158, 0.77465459, 0.77796046, 0.7741774 ,\n",
       "        0.78091049, 0.77491559, 0.7775874 , 0.77610475, 0.7798938 ,\n",
       "        0.77306906, 0.77779344, 0.77503195, 0.23427447, 0.23535146,\n",
       "        0.23620391, 0.235321  , 0.42407277, 0.42380295, 0.42481232,\n",
       "        0.42379167, 0.52922277, 0.52828294, 0.52924083, 0.5272918 ,\n",
       "        0.59553633, 0.59456266, 0.59440643, 0.59239372, 0.50430607,\n",
       "        0.50645913, 0.50899009, 0.5035365 , 0.69561746, 0.69614909,\n",
       "        0.69769162, 0.69019153, 0.74682289, 0.74738533, 0.74798517,\n",
       "        0.74027457, 0.76730357, 0.7683255 , 0.76776104, 0.75983839,\n",
       "        0.62800652, 0.62682827, 0.62909867, 0.62397138, 0.75578359,\n",
       "        0.75597863, 0.75594449, 0.75105685, 0.77627831, 0.77662677,\n",
       "        0.77604524, 0.7707474 , 0.78295691, 0.78337069, 0.78375931,\n",
       "        0.77815244, 0.53987075, 0.60426855, 0.63843968, 0.68825587,\n",
       "        0.48857194, 0.56444536, 0.60919914, 0.6719673 , 0.45840436,\n",
       "        0.54833404, 0.60504278, 0.66657227, 0.44213156, 0.53407277,\n",
       "        0.59662482, 0.66344684, 0.73665006, 0.73731165, 0.74412371,\n",
       "        0.7547673 , 0.7125232 , 0.70848185, 0.71327872, 0.73321407,\n",
       "        0.69496045, 0.6968101 , 0.7049545 , 0.72410419, 0.68372618,\n",
       "        0.69139632, 0.69895384, 0.72033645, 0.78751676, 0.78302721,\n",
       "        0.78382471, 0.78232546, 0.80200365, 0.7990049 , 0.79829395,\n",
       "        0.79943398, 0.79330055, 0.78928604, 0.7870605 , 0.79046359,\n",
       "        0.78633976, 0.78323828, 0.7819949 , 0.78372247, 0.31951014,\n",
       "        0.3216615 , 0.32134982, 0.32250324, 0.54544489, 0.54620762,\n",
       "        0.54650155, 0.54725108, 0.64475135, 0.64385687, 0.64455076,\n",
       "        0.64446611, 0.7008114 , 0.6994506 , 0.69964428, 0.69850581,\n",
       "        0.61943752, 0.62094496, 0.62094272, 0.61977121, 0.77578305,\n",
       "        0.77577773, 0.77449095, 0.77319117, 0.79689058, 0.79621891,\n",
       "        0.79511101, 0.79277766, 0.80402498, 0.80342752, 0.80271813,\n",
       "        0.79998493, 0.72484369, 0.7252478 , 0.72311062, 0.7227309 ,\n",
       "        0.80473778, 0.80307014, 0.80138227, 0.80124549, 0.80485225,\n",
       "        0.80236686, 0.80206327, 0.80188305, 0.8023905 , 0.80113693,\n",
       "        0.80111339, 0.80122107, 0.53987075, 0.60426855, 0.63843968,\n",
       "        0.68825587, 0.48857194, 0.56444536, 0.60919914, 0.6719673 ,\n",
       "        0.45840436, 0.54833404, 0.60504278, 0.66657227, 0.44213156,\n",
       "        0.53407277, 0.59662482, 0.66344684, 0.73665006, 0.73731165,\n",
       "        0.74412371, 0.7547673 , 0.7125232 , 0.70848185, 0.71327872,\n",
       "        0.73321407, 0.69496045, 0.6968101 , 0.7049545 , 0.72410419,\n",
       "        0.68372618, 0.69139632, 0.69895384, 0.72033645, 0.78751676,\n",
       "        0.78302721, 0.78382471, 0.78232546, 0.80200365, 0.7990049 ,\n",
       "        0.79829395, 0.79943398, 0.79330055, 0.78928604, 0.7870605 ,\n",
       "        0.79046359, 0.78633976, 0.78323828, 0.7819949 , 0.78372247,\n",
       "        0.31951014, 0.3216615 , 0.32134982, 0.32250324, 0.54544489,\n",
       "        0.54620762, 0.54650155, 0.54725108, 0.64475135, 0.64385687,\n",
       "        0.64455076, 0.64446611, 0.7008114 , 0.6994506 , 0.69964428,\n",
       "        0.69850581, 0.61943752, 0.62094496, 0.62094272, 0.61977121,\n",
       "        0.77578305, 0.77577773, 0.77449095, 0.77319117, 0.79689058,\n",
       "        0.79621891, 0.79511101, 0.79277766, 0.80402498, 0.80342752,\n",
       "        0.80271813, 0.79998493, 0.72484369, 0.7252478 , 0.72311062,\n",
       "        0.7227309 , 0.80473778, 0.80307014, 0.80138227, 0.80124549,\n",
       "        0.80485225, 0.80236686, 0.80206327, 0.80188305, 0.8023905 ,\n",
       "        0.80113693, 0.80111339, 0.80122107, 0.54049038, 0.6253963 ,\n",
       "        0.66015319, 0.727663  , 0.48929614, 0.58456912, 0.64017516,\n",
       "        0.7182412 , 0.46783067, 0.57834961, 0.63916417, 0.71437916,\n",
       "        0.45544527, 0.57653854, 0.63481337, 0.70885423, 0.73712775,\n",
       "        0.75987744, 0.76105522, 0.77237878, 0.71795993, 0.73720629,\n",
       "        0.7424117 , 0.75840135, 0.71033057, 0.73207092, 0.73807206,\n",
       "        0.7548359 , 0.70547798, 0.72885634, 0.7359    , 0.75175211,\n",
       "        0.82587321, 0.82879128, 0.82593082, 0.82705718, 0.81127185,\n",
       "        0.81316211, 0.81322148, 0.81492457, 0.79877806, 0.79819731,\n",
       "        0.8002915 , 0.80544218, 0.79149629, 0.79258497, 0.79344213,\n",
       "        0.79887376, 0.43027483, 0.43034419, 0.43113488, 0.43145736,\n",
       "        0.66227176, 0.66161993, 0.6623255 , 0.66217126, 0.75116708,\n",
       "        0.75055641, 0.75082215, 0.75030774, 0.79128951, 0.79034803,\n",
       "        0.7908819 , 0.78963994, 0.73828144, 0.73981571, 0.73996636,\n",
       "        0.73853964, 0.82687562, 0.8268248 , 0.82617282, 0.82484157,\n",
       "        0.83209329, 0.83094029, 0.82969369, 0.8287594 , 0.82878911,\n",
       "        0.82763523, 0.82726849, 0.82631606, 0.81147568, 0.81204295,\n",
       "        0.81044768, 0.80979503, 0.83138393, 0.83050746, 0.82938011,\n",
       "        0.82919701, 0.8246431 , 0.8223525 , 0.8227077 , 0.82328569,\n",
       "        0.81705447, 0.81671913, 0.81634294, 0.81706177]),\n",
       " 'std_test_score': array([0.1379091 , 0.10293762, 0.05594344, 0.02843187, 0.11828935,\n",
       "        0.09314416, 0.06716495, 0.03888857, 0.14646178, 0.09640863,\n",
       "        0.08347978, 0.03474045, 0.17293336, 0.10053583, 0.0790098 ,\n",
       "        0.03703207, 0.05048522, 0.04620488, 0.03411115, 0.03672477,\n",
       "        0.04717905, 0.05354515, 0.0314599 , 0.03949211, 0.04854592,\n",
       "        0.04243471, 0.03372766, 0.03893398, 0.05535245, 0.04670918,\n",
       "        0.03971445, 0.04017353, 0.0118786 , 0.009737  , 0.01227849,\n",
       "        0.01074513, 0.01669462, 0.01551263, 0.01878386, 0.01685363,\n",
       "        0.01892613, 0.01508347, 0.02124223, 0.01938531, 0.02053547,\n",
       "        0.01742689, 0.02222557, 0.02095471, 0.01030872, 0.0091894 ,\n",
       "        0.0106943 , 0.00902248, 0.01189873, 0.00957228, 0.01177606,\n",
       "        0.01016102, 0.01220204, 0.01024396, 0.0118804 , 0.01004407,\n",
       "        0.01236085, 0.01083206, 0.01212338, 0.00977185, 0.01274289,\n",
       "        0.01174264, 0.01156256, 0.0103537 , 0.01381394, 0.01069188,\n",
       "        0.01222113, 0.01218226, 0.0133038 , 0.01002253, 0.01109323,\n",
       "        0.01134172, 0.01493216, 0.0118189 , 0.01272678, 0.01233762,\n",
       "        0.01107224, 0.00925603, 0.01061663, 0.01023204, 0.01323906,\n",
       "        0.01219717, 0.01381991, 0.01324778, 0.01398827, 0.01243746,\n",
       "        0.01451838, 0.01468277, 0.01557298, 0.01563991, 0.01592841,\n",
       "        0.01566646, 0.05075752, 0.04067224, 0.05542941, 0.03099431,\n",
       "        0.06005086, 0.05161122, 0.06945246, 0.03292345, 0.05728903,\n",
       "        0.05938576, 0.06870261, 0.03420277, 0.05998213, 0.06411063,\n",
       "        0.07331331, 0.0351272 , 0.02557025, 0.02010337, 0.01844358,\n",
       "        0.01732516, 0.02606596, 0.02150452, 0.02984163, 0.01286328,\n",
       "        0.03645413, 0.01841154, 0.03198845, 0.01155172, 0.04429499,\n",
       "        0.01971653, 0.03538341, 0.01340187, 0.019013  , 0.01591767,\n",
       "        0.01868008, 0.01874497, 0.02163696, 0.01635021, 0.02169104,\n",
       "        0.02089297, 0.02391691, 0.01944017, 0.02243805, 0.02245287,\n",
       "        0.02427351, 0.02014253, 0.02277408, 0.02253177, 0.01179085,\n",
       "        0.01014116, 0.01103649, 0.01012988, 0.0156398 , 0.01424978,\n",
       "        0.01426332, 0.01511787, 0.01678192, 0.01489912, 0.01545092,\n",
       "        0.01671205, 0.01798899, 0.01561838, 0.01642082, 0.01720755,\n",
       "        0.01330831, 0.01141733, 0.01333413, 0.01477063, 0.01760277,\n",
       "        0.01660671, 0.01719223, 0.01931634, 0.01741648, 0.01649459,\n",
       "        0.01565504, 0.01861963, 0.01811549, 0.01754254, 0.0163512 ,\n",
       "        0.01958509, 0.01724932, 0.01256166, 0.01409016, 0.01614012,\n",
       "        0.02268205, 0.01901852, 0.01896012, 0.02128723, 0.0230449 ,\n",
       "        0.01983909, 0.01944459, 0.02189034, 0.02410458, 0.02119993,\n",
       "        0.02054156, 0.02234119, 0.05075752, 0.04067224, 0.05542941,\n",
       "        0.03099431, 0.06005086, 0.05161122, 0.06945246, 0.03292345,\n",
       "        0.05728903, 0.05938576, 0.06870261, 0.03420277, 0.05998213,\n",
       "        0.06411063, 0.07331331, 0.0351272 , 0.02557025, 0.02010337,\n",
       "        0.01844358, 0.01732516, 0.02606596, 0.02150452, 0.02984163,\n",
       "        0.01286328, 0.03645413, 0.01841154, 0.03198845, 0.01155172,\n",
       "        0.04429499, 0.01971653, 0.03538341, 0.01340187, 0.019013  ,\n",
       "        0.01591767, 0.01868008, 0.01874497, 0.02163696, 0.01635021,\n",
       "        0.02169104, 0.02089297, 0.02391691, 0.01944017, 0.02243805,\n",
       "        0.02245287, 0.02427351, 0.02014253, 0.02277408, 0.02253177,\n",
       "        0.01179085, 0.01014116, 0.01103649, 0.01012988, 0.0156398 ,\n",
       "        0.01424978, 0.01426332, 0.01511787, 0.01678192, 0.01489912,\n",
       "        0.01545092, 0.01671205, 0.01798899, 0.01561838, 0.01642082,\n",
       "        0.01720755, 0.01330831, 0.01141733, 0.01333413, 0.01477063,\n",
       "        0.01760277, 0.01660671, 0.01719223, 0.01931634, 0.01741648,\n",
       "        0.01649459, 0.01565504, 0.01861963, 0.01811549, 0.01754254,\n",
       "        0.0163512 , 0.01958509, 0.01724932, 0.01256166, 0.01409016,\n",
       "        0.01614012, 0.02268205, 0.01901852, 0.01896012, 0.02128723,\n",
       "        0.0230449 , 0.01983909, 0.01944459, 0.02189034, 0.02410458,\n",
       "        0.02119993, 0.02054156, 0.02234119, 0.04010752, 0.03975511,\n",
       "        0.03901212, 0.03440357, 0.04441889, 0.03665628, 0.04063445,\n",
       "        0.03450304, 0.060221  , 0.03832492, 0.04572821, 0.03611739,\n",
       "        0.07593091, 0.05274243, 0.05497693, 0.03768782, 0.02326126,\n",
       "        0.02277065, 0.02371527, 0.02828337, 0.02685988, 0.02017855,\n",
       "        0.02651988, 0.02935451, 0.03010618, 0.02473156, 0.02576161,\n",
       "        0.02904268, 0.03009978, 0.02540161, 0.02865788, 0.02839558,\n",
       "        0.02896593, 0.02620026, 0.02365901, 0.02981554, 0.02994722,\n",
       "        0.02481478, 0.02469024, 0.02839163, 0.02900176, 0.02597161,\n",
       "        0.02620369, 0.02838013, 0.02926107, 0.02472585, 0.0273573 ,\n",
       "        0.02772983, 0.01681292, 0.01537137, 0.01624435, 0.01605229,\n",
       "        0.023139  , 0.02257847, 0.02236702, 0.02263613, 0.02473727,\n",
       "        0.02457887, 0.02376913, 0.02388821, 0.02535055, 0.02517465,\n",
       "        0.02460336, 0.02416372, 0.02321071, 0.0210859 , 0.02385823,\n",
       "        0.02345248, 0.02691084, 0.0253311 , 0.02577443, 0.02707866,\n",
       "        0.0280768 , 0.02624824, 0.02612517, 0.02710077, 0.02874438,\n",
       "        0.02651877, 0.02659691, 0.02706075, 0.02546467, 0.0232741 ,\n",
       "        0.0239808 , 0.02380458, 0.02819864, 0.02560292, 0.02675382,\n",
       "        0.02590282, 0.02904917, 0.02614946, 0.02722664, 0.02560511,\n",
       "        0.02962898, 0.02644223, 0.02721136, 0.02546455]),\n",
       " 'rank_test_score': array([377, 363, 351, 330, 382, 366, 362, 341, 383, 375, 364, 345, 384,\n",
       "        376, 365, 346, 270, 252, 244, 243, 271, 251, 247, 248, 280, 255,\n",
       "        259, 256, 285, 269, 268, 266, 208, 211, 206, 209, 128, 141, 127,\n",
       "        144, 124, 140, 130, 133, 125, 147, 129, 139, 381, 379, 378, 380,\n",
       "        359, 360, 358, 361, 334, 335, 333, 336, 308, 309, 310, 311, 339,\n",
       "        338, 337, 340, 237, 236, 233, 242, 171, 170, 169, 175, 152, 150,\n",
       "        151, 155, 288, 289, 287, 291, 159, 157, 158, 165, 132, 131, 134,\n",
       "        149, 119, 114, 111, 126, 328, 304, 283, 245, 343, 315, 300, 253,\n",
       "        348, 317, 302, 257, 352, 331, 306, 260, 185, 181, 172, 161, 214,\n",
       "        218, 212, 188, 238, 234, 221, 197, 249, 240, 229, 203, 103, 117,\n",
       "        109, 120,  56,  75,  79,  73,  89, 101, 105,  97, 107, 115, 122,\n",
       "        112, 373, 369, 371, 367, 325, 323, 321, 319, 272, 278, 274, 276,\n",
       "        223, 227, 225, 231, 298, 292, 294, 296, 135, 137, 142, 145,  82,\n",
       "         84,  86,  91,  42,  44,  48,  71, 195, 193, 199, 201,  40,  46,\n",
       "         60,  62,  38,  52,  54,  58,  50,  66,  68,  64, 328, 304, 283,\n",
       "        245, 343, 315, 300, 253, 348, 317, 302, 257, 352, 331, 306, 260,\n",
       "        185, 181, 172, 161, 214, 218, 212, 188, 238, 234, 221, 197, 249,\n",
       "        240, 229, 203, 103, 117, 109, 120,  56,  75,  79,  73,  89, 101,\n",
       "        105,  97, 107, 115, 122, 112, 373, 369, 371, 367, 325, 323, 321,\n",
       "        319, 272, 278, 274, 276, 223, 227, 225, 231, 298, 292, 294, 296,\n",
       "        135, 137, 142, 145,  82,  84,  86,  91,  42,  44,  48,  71, 195,\n",
       "        193, 199, 201,  40,  46,  60,  62,  38,  52,  54,  58,  50,  66,\n",
       "         68,  64, 327, 290, 267, 192, 342, 312, 281, 205, 347, 313, 282,\n",
       "        210, 350, 314, 286, 217, 184, 154, 153, 148, 207, 183, 174, 156,\n",
       "        216, 190, 180, 160, 220, 191, 187, 163,  19,   8,  18,  13,  34,\n",
       "         31,  30,  29,  78,  81,  70,  37,  94,  93,  88,  77, 357, 356,\n",
       "        355, 354, 263, 265, 262, 264, 164, 167, 166, 168,  95,  99,  96,\n",
       "        100, 179, 177, 176, 178,  14,  15,  17,  20,   1,   3,   5,  10,\n",
       "          9,  11,  12,  16,  33,  32,  35,  36,   2,   4,   6,   7,  21,\n",
       "         24,  23,  22,  26,  27,  28,  25], dtype=int32)}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_result = grid_model.cv_results_\n",
    "grid_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54dd9870-405e-4692-bc75-3120c6c79643",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.075049</td>\n",
       "      <td>0.006150</td>\n",
       "      <td>0.011106</td>\n",
       "      <td>0.000772</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'colsample_bytree': 0.5, 'learning_rate': 1.0...</td>\n",
       "      <td>0.311775</td>\n",
       "      <td>0.102994</td>\n",
       "      <td>0.095541</td>\n",
       "      <td>0.411411</td>\n",
       "      <td>0.393558</td>\n",
       "      <td>0.263056</td>\n",
       "      <td>0.137909</td>\n",
       "      <td>377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.073436</td>\n",
       "      <td>0.003944</td>\n",
       "      <td>0.012208</td>\n",
       "      <td>0.001254</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>50</td>\n",
       "      <td>0.6</td>\n",
       "      <td>{'colsample_bytree': 0.5, 'learning_rate': 1.0...</td>\n",
       "      <td>0.522880</td>\n",
       "      <td>0.367664</td>\n",
       "      <td>0.235337</td>\n",
       "      <td>0.487982</td>\n",
       "      <td>0.453828</td>\n",
       "      <td>0.413538</td>\n",
       "      <td>0.102938</td>\n",
       "      <td>363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.082494</td>\n",
       "      <td>0.007282</td>\n",
       "      <td>0.013194</td>\n",
       "      <td>0.002367</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>50</td>\n",
       "      <td>0.7</td>\n",
       "      <td>{'colsample_bytree': 0.5, 'learning_rate': 1.0...</td>\n",
       "      <td>0.505397</td>\n",
       "      <td>0.366355</td>\n",
       "      <td>0.422187</td>\n",
       "      <td>0.433173</td>\n",
       "      <td>0.517324</td>\n",
       "      <td>0.448887</td>\n",
       "      <td>0.055943</td>\n",
       "      <td>351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.075899</td>\n",
       "      <td>0.001936</td>\n",
       "      <td>0.013763</td>\n",
       "      <td>0.002965</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>50</td>\n",
       "      <td>0.9</td>\n",
       "      <td>{'colsample_bytree': 0.5, 'learning_rate': 1.0...</td>\n",
       "      <td>0.557011</td>\n",
       "      <td>0.539469</td>\n",
       "      <td>0.488406</td>\n",
       "      <td>0.573008</td>\n",
       "      <td>0.540988</td>\n",
       "      <td>0.539776</td>\n",
       "      <td>0.028432</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.122824</td>\n",
       "      <td>0.009979</td>\n",
       "      <td>0.011784</td>\n",
       "      <td>0.000728</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'colsample_bytree': 0.5, 'learning_rate': 1.0...</td>\n",
       "      <td>0.200974</td>\n",
       "      <td>0.090469</td>\n",
       "      <td>0.154276</td>\n",
       "      <td>0.435050</td>\n",
       "      <td>0.273289</td>\n",
       "      <td>0.230812</td>\n",
       "      <td>0.118289</td>\n",
       "      <td>382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>0.302176</td>\n",
       "      <td>0.023510</td>\n",
       "      <td>0.015031</td>\n",
       "      <td>0.002655</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.05</td>\n",
       "      <td>150</td>\n",
       "      <td>0.9</td>\n",
       "      <td>{'colsample_bytree': 0.9, 'learning_rate': 0.0...</td>\n",
       "      <td>0.851339</td>\n",
       "      <td>0.828379</td>\n",
       "      <td>0.810648</td>\n",
       "      <td>0.845398</td>\n",
       "      <td>0.780665</td>\n",
       "      <td>0.823286</td>\n",
       "      <td>0.025605</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>0.365333</td>\n",
       "      <td>0.017098</td>\n",
       "      <td>0.015666</td>\n",
       "      <td>0.001699</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.05</td>\n",
       "      <td>200</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'colsample_bytree': 0.9, 'learning_rate': 0.0...</td>\n",
       "      <td>0.847008</td>\n",
       "      <td>0.816910</td>\n",
       "      <td>0.804603</td>\n",
       "      <td>0.848291</td>\n",
       "      <td>0.768460</td>\n",
       "      <td>0.817054</td>\n",
       "      <td>0.029629</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>0.392582</td>\n",
       "      <td>0.021700</td>\n",
       "      <td>0.017973</td>\n",
       "      <td>0.003305</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.05</td>\n",
       "      <td>200</td>\n",
       "      <td>0.6</td>\n",
       "      <td>{'colsample_bytree': 0.9, 'learning_rate': 0.0...</td>\n",
       "      <td>0.842684</td>\n",
       "      <td>0.818227</td>\n",
       "      <td>0.807444</td>\n",
       "      <td>0.843452</td>\n",
       "      <td>0.771788</td>\n",
       "      <td>0.816719</td>\n",
       "      <td>0.026442</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>0.368410</td>\n",
       "      <td>0.010499</td>\n",
       "      <td>0.014438</td>\n",
       "      <td>0.000850</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.05</td>\n",
       "      <td>200</td>\n",
       "      <td>0.7</td>\n",
       "      <td>{'colsample_bytree': 0.9, 'learning_rate': 0.0...</td>\n",
       "      <td>0.839184</td>\n",
       "      <td>0.822784</td>\n",
       "      <td>0.805868</td>\n",
       "      <td>0.844705</td>\n",
       "      <td>0.769174</td>\n",
       "      <td>0.816343</td>\n",
       "      <td>0.027211</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>0.387971</td>\n",
       "      <td>0.011221</td>\n",
       "      <td>0.014624</td>\n",
       "      <td>0.002567</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.05</td>\n",
       "      <td>200</td>\n",
       "      <td>0.9</td>\n",
       "      <td>{'colsample_bytree': 0.9, 'learning_rate': 0.0...</td>\n",
       "      <td>0.843116</td>\n",
       "      <td>0.820177</td>\n",
       "      <td>0.806039</td>\n",
       "      <td>0.841661</td>\n",
       "      <td>0.774317</td>\n",
       "      <td>0.817062</td>\n",
       "      <td>0.025465</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>384 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0         0.075049      0.006150         0.011106        0.000772   \n",
       "1         0.073436      0.003944         0.012208        0.001254   \n",
       "2         0.082494      0.007282         0.013194        0.002367   \n",
       "3         0.075899      0.001936         0.013763        0.002965   \n",
       "4         0.122824      0.009979         0.011784        0.000728   \n",
       "..             ...           ...              ...             ...   \n",
       "379       0.302176      0.023510         0.015031        0.002655   \n",
       "380       0.365333      0.017098         0.015666        0.001699   \n",
       "381       0.392582      0.021700         0.017973        0.003305   \n",
       "382       0.368410      0.010499         0.014438        0.000850   \n",
       "383       0.387971      0.011221         0.014624        0.002567   \n",
       "\n",
       "     param_colsample_bytree  param_learning_rate  param_n_estimators  \\\n",
       "0                       0.5                 1.00                  50   \n",
       "1                       0.5                 1.00                  50   \n",
       "2                       0.5                 1.00                  50   \n",
       "3                       0.5                 1.00                  50   \n",
       "4                       0.5                 1.00                 100   \n",
       "..                      ...                  ...                 ...   \n",
       "379                     0.9                 0.05                 150   \n",
       "380                     0.9                 0.05                 200   \n",
       "381                     0.9                 0.05                 200   \n",
       "382                     0.9                 0.05                 200   \n",
       "383                     0.9                 0.05                 200   \n",
       "\n",
       "     param_subsample                                             params  \\\n",
       "0                0.5  {'colsample_bytree': 0.5, 'learning_rate': 1.0...   \n",
       "1                0.6  {'colsample_bytree': 0.5, 'learning_rate': 1.0...   \n",
       "2                0.7  {'colsample_bytree': 0.5, 'learning_rate': 1.0...   \n",
       "3                0.9  {'colsample_bytree': 0.5, 'learning_rate': 1.0...   \n",
       "4                0.5  {'colsample_bytree': 0.5, 'learning_rate': 1.0...   \n",
       "..               ...                                                ...   \n",
       "379              0.9  {'colsample_bytree': 0.9, 'learning_rate': 0.0...   \n",
       "380              0.5  {'colsample_bytree': 0.9, 'learning_rate': 0.0...   \n",
       "381              0.6  {'colsample_bytree': 0.9, 'learning_rate': 0.0...   \n",
       "382              0.7  {'colsample_bytree': 0.9, 'learning_rate': 0.0...   \n",
       "383              0.9  {'colsample_bytree': 0.9, 'learning_rate': 0.0...   \n",
       "\n",
       "     split0_test_score  split1_test_score  split2_test_score  \\\n",
       "0             0.311775           0.102994           0.095541   \n",
       "1             0.522880           0.367664           0.235337   \n",
       "2             0.505397           0.366355           0.422187   \n",
       "3             0.557011           0.539469           0.488406   \n",
       "4             0.200974           0.090469           0.154276   \n",
       "..                 ...                ...                ...   \n",
       "379           0.851339           0.828379           0.810648   \n",
       "380           0.847008           0.816910           0.804603   \n",
       "381           0.842684           0.818227           0.807444   \n",
       "382           0.839184           0.822784           0.805868   \n",
       "383           0.843116           0.820177           0.806039   \n",
       "\n",
       "     split3_test_score  split4_test_score  mean_test_score  std_test_score  \\\n",
       "0             0.411411           0.393558         0.263056        0.137909   \n",
       "1             0.487982           0.453828         0.413538        0.102938   \n",
       "2             0.433173           0.517324         0.448887        0.055943   \n",
       "3             0.573008           0.540988         0.539776        0.028432   \n",
       "4             0.435050           0.273289         0.230812        0.118289   \n",
       "..                 ...                ...              ...             ...   \n",
       "379           0.845398           0.780665         0.823286        0.025605   \n",
       "380           0.848291           0.768460         0.817054        0.029629   \n",
       "381           0.843452           0.771788         0.816719        0.026442   \n",
       "382           0.844705           0.769174         0.816343        0.027211   \n",
       "383           0.841661           0.774317         0.817062        0.025465   \n",
       "\n",
       "     rank_test_score  \n",
       "0                377  \n",
       "1                363  \n",
       "2                351  \n",
       "3                330  \n",
       "4                382  \n",
       "..               ...  \n",
       "379               22  \n",
       "380               26  \n",
       "381               27  \n",
       "382               28  \n",
       "383               25  \n",
       "\n",
       "[384 rows x 17 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = pd.DataFrame.from_dict(grid_result)\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9710557e-fbbc-4b64-bad0-883069455547",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.9,\n",
       " 'learning_rate': 0.03,\n",
       " 'n_estimators': 150,\n",
       " 'subsample': 0.5}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a7ce81d-f21d-4c10-8c46-d7fe4cdd7f6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=0.9, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             feature_weights=None, gamma=None, grow_policy=None,\n",
       "             importance_type=None, interaction_constraints=None,\n",
       "             learning_rate=0.03, max_bin=None, max_cat_threshold=None,\n",
       "             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "             max_leaves=None, min_child_weight=None, missing=nan,\n",
       "             monotone_constraints=None, multi_strategy=None, n_estimators=150,\n",
       "             n_jobs=None, num_parallel_tree=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>XGBRegressor</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor\">?<span>Documentation for XGBRegressor</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=0.9, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             feature_weights=None, gamma=None, grow_policy=None,\n",
       "             importance_type=None, interaction_constraints=None,\n",
       "             learning_rate=0.03, max_bin=None, max_cat_threshold=None,\n",
       "             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "             max_leaves=None, min_child_weight=None, missing=nan,\n",
       "             monotone_constraints=None, multi_strategy=None, n_estimators=150,\n",
       "             n_jobs=None, num_parallel_tree=None, ...)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=0.9, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             feature_weights=None, gamma=None, grow_policy=None,\n",
       "             importance_type=None, interaction_constraints=None,\n",
       "             learning_rate=0.03, max_bin=None, max_cat_threshold=None,\n",
       "             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "             max_leaves=None, min_child_weight=None, missing=nan,\n",
       "             monotone_constraints=None, multi_strategy=None, n_estimators=150,\n",
       "             n_jobs=None, num_parallel_tree=None, ...)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_model.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a483980f-e4dc-4bd5-842d-8c05133c4ee8",
   "metadata": {},
   "source": [
    "## Model Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aaffb9fd-fe57-4a44-87a3-3d54bb9b304a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.8320932865142823)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"  \n",
    "parameter                                                                       Accuracy\n",
    "{'colsample_bytree': 0.9,\n",
    " 'learning_rate': 0.03,\n",
    " 'n_estimators': 150,\n",
    " 'subsample': 0.5}                                                         - 0.8320932865142823 \n",
    "\"\"\"\n",
    "\n",
    "grid_model.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cdc643-5c16-4770-bbf7-f27fd2f7f9b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "711a10b9-cd97-4d2f-88fa-9c94bf3e2745",
   "metadata": {},
   "source": [
    "## save the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "05699548-8401-4c3b-a0f9-8cdfea819326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle \n",
    "# pickle.dump(regressor, open(\"XGBoost_finalmodel_insurance_charge_predict.sav \",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ccdfa7-8c6f-4230-aa1d-8f802d0c12e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6bc1445a-b799-4ea1-b8f3-5fe9d54afcc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10980.673], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_model.predict([[ 52, 30.200, 1, 1, 0 ]])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f718416d-f268-4846-ab64-9e118e010765",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b36c62c-db33-4086-ae60-944d15ccf976",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
